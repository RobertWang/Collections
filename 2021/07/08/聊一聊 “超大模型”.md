> 本文由 [简悦 SimpRead](http://ksria.com/simpread/) 转码， 原文地址 [mp.weixin.qq.com](https://mp.weixin.qq.com/s?__biz=MzU3NDgxMzI0Mw==&mid=2247498411&idx=3&sn=c1e78544493e4fafec100fd747f305dd&chksm=fd2e1fffca5996e9b22a52e9881fe61c45ec7360c0f64cce519452bc8afcec167e4f7bdd6619&mpshare=1&scene=1&srcid=0708W5gDwr8qRYiolNqa9rfz&sharer_sharetime=1625740211702&sharer_shareid=7fece245937ac96f04f0fb8e1311fff1#rd)

> > > > 文 | 金雪锋  
> > > > 源 | 知乎  

最近经常被问，你看 “万亿的模型都出来了，你们训练的千亿模型是不是落伍了？” 我想说：“虽然都叫超大模型，但是类型是不一样的，虽说每一类模型训出来都不容易，不过澄清一下概念还是必要的”。

1.  **稠密 Transformer：** OpenAI GPT-3，华为盘古 / 鹏程盘古α（MindSpore 支撑）；模型规模的扩展是全结构的扩容；
    
2.  **稀疏 MoE 结构 Transformer：** Google Switch Transformer，智源悟道 2.0，阿里 M6。一般来说是选择一个基础的稠密模型，通过 MoE 稀疏结构扩展 FFN 部分，以此来达成模型的扩容；
    
3.  **高维稀疏特征推荐模型：** 快手推荐精排，我理解主要是推荐的高维稀疏特征 Embedding 需要超大参数；
    

![](https://mmbiz.qpic.cn/mmbiz_jpg/5fknb41ib9qEunKnAq0BRibd6Ojoz6LdPeTL8RI2rrCXbyzkSuYBib3AImQ95acZbZYib3RroNy59OnTNTP3ic4BLxA/640?wx_fmt=jpeg)

所以我们不能单纯从参数规模来衡量一个网络的效果，需要通过参数量和计算量来综合对比，需要我们探索一种新的指标，综合考虑内存和算力开销来评估一个模型。

另外，**从 Switch Transformer 1.6 万亿模型来看，其计算量只有稠密 T5 130 亿参数的 10%，参数量是其 100 倍**；如果从每个参数消耗的算力来计算，1.6 万亿稀疏模型只是稠密的千分之一，即 1.6 万亿参数的 Switch Transformer 的计算量相当于 10 亿参数的稠密的 Transformer。

那么从训练角度来看，MoE 大模型的计算量较少，重点是做好模型参数的切分，从 switch transformer 的实践看，主要使用数据并行 + MoE 并行的组合；而稠密的 Transformer 计算和通信量非常大，所以盘古 -α需要在 2K 张卡上进行训练，同时也需要复杂的 pipeline 并行 / 算子级模型并行 / 数据并行等并行切分策略来确保 2k 集群的算力能被充分利用，个人认为训练挑战更大。

从推理的角度看，MoE 的模型参数量非常大，我觉得可能需要通过蒸馏 / 量化等手段进行压缩才更适合使用，挑战很大，也是 MoE 模型推广面临的障碍。

![](https://mmbiz.qpic.cn/mmbiz_jpg/5fknb41ib9qEunKnAq0BRibd6Ojoz6LdPeZoWq0KrEh9kHsE5Rog0qZJCpkdOQSuMCHXibIv1r0nAYhSGaF1GDndw/640?wx_fmt=jpeg)

快手的 1.9 万亿参数网络，是一种高维稀疏推荐网络，拿 Google Wide&Deep 来对比更为恰当。快手推荐网络的优化，应该是在后面的 DNN 层用了 Transformer 结构，而模型头部的 Embedding 部分还是保持和传统深度学习推荐网络类似（没有找到相关论文，不对请指正）。这类型网络，为了表达高维稀疏特征，会有一个超级大的 Embedding，参数主要是集中在头部的特征 Embedding 部分。这种类型网络的训练方式和前面讲的完全不同，核心技术是 Embedding 的模型并行，以及 CPU/NPU 的协同计算和存储。华为诺亚实验室在今年 SIGIR 2021 上发表的 “ScaleFreeCTR: MixCache-based Distributed Training System for CTR Models with Huge Embedding Table” 是目前一种最好的训练方案之一，也将会在 MindSpore 上开源。这里就不再展开分析。

除了 Transformer 这种算法结构外，还是有 CNN 类的超大模型，也可以分成两类，这两类模型也是稠密的，参数量和计算量是成正比。

1.  超大分类层：超大规模人脸识别、图像分类网络，其典型特征是 CNN 特征抽取之后的 FC 分类层超级大。例如千万 ID 的人脸识别，FC 层的参数规模就达到了 50 亿。
    
2.  超大 Activation：遥感和超高分辨率图像处理，这类网络参数量不大，和传统 CNN 的参数量类似，在百 M 级别。但是这种模型的输入数据以及计算过程中的 Activation 非常大。以遥感为例，平均输入样本的分辨率就有 [30000, 30000, 4]，一个样本就有 3.6GB，大的图像有 10GB 以上，中间层 Activation 也是 GB 级别的大小。
    

所以，总的来说在 NLP、多模态、推荐、图像处理领域都有大模型，目前业界比较火热讨论的主要是基于 Transformer+MoE 结构的 NLP 及多模态大模型，我们期望通过这篇文章，让小伙伴能了解这些模型在计算上的差异。