> 本文由 [简悦 SimpRead](http://ksria.com/simpread/) 转码， 原文地址 [mp.weixin.qq.com](https://mp.weixin.qq.com/s?__biz=MzA3OTc0MzY1Mg==&mid=2247512355&idx=4&sn=0849b042533439420ec56bef5ef238bb&chksm=9fac2ee8a8dba7fea611ca71b84d40b1aed095bd6ebeff7779e95fe0be060ff7ace178d651ae&mpshare=1&scene=1&srcid=0713rojUieOmMllus7qNp8JT&sharer_sharetime=1626142423911&sharer_shareid=7fece245937ac96f04f0fb8e1311fff1#rd)

作者 | Natan Silnitsky  

1 消费与投影

*   首先，他们将所有数据库的站点元数据对象以流的方式传输到 Kafka 主题中，包括新站点创建和站点更新。一致性可以通过在 Kafka Consumer 中进行 DB 插入来实现，或者通过使用 CDC 产品（如 Debezium）来实现。
    
*   其次，他们创建了一个有自己数据库的 “只写” 服务（反向查找写入器），该服务使用站点元数据对象，但只获取已安装应用上下文并写入数据库。即将站点元数据的某个“视图”（已安装的应用程序）投影到数据库中。
    

*   第三，他们创建了一个 “只读” 服务，只接受与已安装应用上下文相关的请求，通过查询存储着 “已安装应用程序” 视图的数据库来满足请求。
    

 效果

*   通过将数据以流的方式传输到 Kafka，MetaSite 服务完全同数据消费者解耦，这大大降低了服务和 DB 的负载。
    
*   通过消费来自 Kafka 的数据，并为特定的上下文创建一个 “物化视图”，反向查找写入器服务能够创建一个最终一致的数据投影，大幅优化了客户端服务的查询需求。
    
*   将读服务与写服务分开，可以方便地扩展只读 DB 副本和服务实例的数量，这些实例可以处理来自全球多个数据中心的不断增长的查询负载。
    

这个过程涉及到两个服务：Contacts Jobs 服务处理导入请求并创建导入批处理作业，Contacts Importer 执行实际的格式化并存储联系人（有时借助第三方服务）。

而使用 Kafka 和 WebSocket 管理者服务，我们可以实现一个完全分布式的事件驱动过程，其中每个服务都是完全独立工作的。

使用 Kafka 和 WebSocket 的 E2E 事件驱动

它需要提供一个 channel-Id，以便 WebSocket 服务能够将通知路由回正确的浏览器：

打开 WebSocket 通知 “通道”

第三，Jobs 服务在处理完请求后，会生成并向 Kafka 主题发送作业请求。

HTTP Import 请求和生成的 Import Job 消息

 效果

*   使用这种设计，在导入过程的各个阶段通知浏览器变得很简单，而且不需要保持任何状态，也不需要任何轮询。
    
*   Kafka 的使用使得导入过程更具弹性和可扩展性，因为多个服务可以处理来自同一个原始导入 http 请求的作业。
    
*   使用 Kafka 复制，很容易将每个阶段放在最合适的数据中心和地理位置。也许导入器服务需要在谷歌 DC 上，以便可以更快地导入谷歌联系人。
    
*   WebSocket 服务的传入通知请求也可以生成到 Kafka，然后复制到 WebSocket 服务所在的数据中心。
    

**针对 0 延迟数据访问**

这个解决方案效果很好，但是通过网络取值存在无法避免的延迟。它更适合于更大的数据集，而不仅仅是配置数据。

Kafka 以压缩主题的形式为键 / 值存储提供了类似的解决方案（保留模型确保键的最新值不会被删除）。

考虑以下用例——两个微服务使用压缩主题来做数据维护：Wix Business Manager（帮助 Wix 网站所有者管理他们的业务）使用一个压缩主题存放支持的国家列表，Wix Bookings（允许安排预约和课程）维护了一个 “（Time Zones）” 压缩主题。从这些内存 KV 存储中检索值的延迟为 0。

各内存 KV 存储以及相应的 Kafka 压缩主题

![](https://mmbiz.qpic.cn/mmbiz_png/FE4VibF0SjfPribEwltWuicicRqe108bRNAHHRY8NibnjnnJ4mqoGBgzWpE0In8pqGJUsFicahRaveRfezGGFiaFLQTEQ/640?wx_fmt=png)  

当 Wix Business Manager 将另一个国家添加到 “国家” 主题时，Wix Bookings 会消费此更新，并自动为 “时区” 主题添加一个新的时区。现在，内存 KV 存储中的 “时区” 也通过更新增加了新的时区：

South Sudan 的时区被加入压缩主题

![](https://mmbiz.qpic.cn/mmbiz_png/FE4VibF0SjfPribEwltWuicicRqe108bRNAHibXzZfVFiawTVUric0e6tFqv6VcY4kDEwKvG2vZqpPv5mpacemj0fDucg/640?wx_fmt=png)  

**当存在需要确保计划事件最终被处理的需求时**

Wix Payments Subscriptions 服务就是一个例子，它管理基于订阅的支付（例如瑜伽课程的订阅）。

为此，Wix 自定义的 Job Scheduler 服务调用由 Payments Subscription 服务预先配置好的 REST 端点。

在某些情况下，消费者和生产者之间可能会产生延迟，如长时间持续出错。在这些情况下，有一个特殊的仪表板用于解除阻塞，并跳过开发人员可以使用的消息。

![](https://mmbiz.qpic.cn/mmbiz_png/FE4VibF0SjfPribEwltWuicicRqe108bRNAHXibhhIdCfq7t6gY21JCQFk8ufiaGicY8ib9tJBTuMxU1eYvSFOibDB5cpGQ/640?wx_fmt=png)  

还有一个死信队列，用于重试次数耗尽的情况。在这种情况下，消息被放在死信队列中，由开发人员手动审查。

https://eng.uber.com/reliable-reprocessing/

https://github.com/wix/greyhound#greyhound

*   Kafka 允许按顺序处理每个键的请求（例如使用 userId 进行续订），简化工作进程逻辑；
    
*   由于 Kafka 重试策略的实现大大提高了容错能力，续期请求的作业调度频率大大降低。
    

**当幂等性很难实现时**

Payments 服务生成一个 Order Purchase Completed 事件到 Kafka。现在，Checkout 服务将消费此消息，并生成自己的 Order Checkout Completed 消息，其中包含购物车中的所有商品。

![](https://mmbiz.qpic.cn/mmbiz_png/FE4VibF0SjfPribEwltWuicicRqe108bRNAHe4MfPXYzoKFcJTmZb5vxDVPQqlwCqvxfvIbEtOgLTQHRCjebKWj2vA/640?wx_fmt=png)  

为什么？因为多次处理相同的 Checkout Completed 事件可能导致多次发货或库存错误。为了防止下游服务出现这种情况，它们将需要存储去重后的状态，例如，轮询一些存储以确保它们以前没有处理过这个 Order Id。

幸运的是，Kafka 为这种流水线事件流提供了一个解决方案，每个事件只处理一次，即使当一个服务有一个消费者 - 生产者对（例如 Checkout），它消费一条消息，并产生一条新消息。

事务期间生成的任何消息将仅在事务完成后才对下游消费者（Inventory Service）可见。

此外，位于 Kafka 流开始位置的 Payment Service Producer 必须转变为幂等（Idempotent）生产者——这意味着代理将丢弃它生成的任何重复消息。

![](https://mmbiz.qpic.cn/mmbiz_png/FE4VibF0SjfPribEwltWuicicRqe108bRNAHUdwM23ibfFJTGrbwexKSS0aeCN2c7fpgkibhTiceV5JN3AibWnicQodJXEg/640?wx_fmt=png)  

https://www.youtube.com/watch?v=7O_UC_i1XY0

在上半部分，我描述了在 Wix 将联系人导入到 Wix CRM 平台的业务流程。后端包括两个服务。一个是作业服务，我们提供一个 CSV 文件，它会生成作业事件到 Kafka。还有一个联系人导入服务，它会消费并执行导入作业。

假设 CSV 文件有时非常大，将工作负载分割成更小的作业，每个作业中需要导入的联系人就会更少，这个过程就会更高效。通过这种方式，这项工作可以在 Contacts Importer 服务的多个实例中并行。但是，当导入工作被拆分为许多较小的作业时，该如何知道何时通知最终用户所有的联系人都已导入？

为了避免竞态条件，Contacts Importer 服务将完成事件写到原子 KV 存储类型的 Jobs-Completed-Store 中。

原子存储确保所有作业完成事件将按顺序处理。它通过创建一个 “Commands” 主题和一个 “Store” 压缩主题来实现。

![](https://mmbiz.qpic.cn/mmbiz_png/FE4VibF0SjfPribEwltWuicicRqe108bRNAHLQNOOH7iaqd1a7JcDsY23LBE55Uq69thjREPVmJmF9872fKfhNu11Gw/640?wx_fmt=png)  

让我们回到 Contacts Importer 服务流。一旦这个服务实例完成了某些作业的处理，它将更新 Job-Completed KVAtomicStore（例如，请求 Id 为 YYY 的导入作业 3 已经完成）：

![](https://mmbiz.qpic.cn/mmbiz_png/FE4VibF0SjfPribEwltWuicicRqe108bRNAHQEsdKI1n4AYp4ksick4ZWVW9pDZmt1CSYfnvrUO8CaIoo5vXb6mTzdg/640?wx_fmt=png)  

Atomic Store 将生成一条新消息到 job-completed-commands 主题，键为 YYY-6，值为 Job 3 Completed。

接下来，Atomic Store 的消费者 - 生产者对将消费此消息，并增加 KV Store 主题中键 YYY-6 的已完成作业计数。

![](https://mmbiz.qpic.cn/mmbiz_png/FE4VibF0SjfPribEwltWuicicRqe108bRNAHWUFZu40rIWicXG7bStf5ibdBBe5YiaibfgoALtmZHw2EiaLFicj1yINypnvw/640?wx_fmt=png)  

注意，“命令” 请求处理必须只发生一次，否则完成计数器可能不正确（错误增量）。为消费者 - 生产者对创建一个 Kafka 事务（如上文的模式 4 所述）对于确保统计准确至关重要。

 AtomicKVStore 值更新回调

最后，一旦 KV 最新生成的已完成作业计数的值与总数匹配（例如 YYY 导入请求有 6 个已完成作业），就可以通知用户（通过 WebSocket，参见本系列文章第一部分的模式 3）导入完成。通知可以作为 KV-store 主题生成动作的副作用，即调用用户提供给 KV 原子存储的回调。

![](https://mmbiz.qpic.cn/mmbiz_png/FE4VibF0SjfPribEwltWuicicRqe108bRNAHWHqAcCpNWpzk2pYY6nAsXqrTFPHYE6SaYWWH5QhZVSUAEFg8EZ8Yag/640?wx_fmt=png)  

*   完成通知逻辑不一定要在 Contacts Importer 服务中，它可以在任何微服务中，因为这个逻辑完全独立于这个过程的其他部分，只依赖于 Kafka 主题。
    
*   不需要进行定期轮询。整个过程都是事件驱动的，即以管道方式处理事件。
    
*   通过使用基于键的排序和恰好一次的 Kafka 事务，避免作业完成通知或重复更新之间的竞态条件。
    
*   Kafka Streams API 非常适合这样的聚合需求，其特性包括 groupBy（按 Import Request Id 分组）， reduce 或 count（已完成作业计数）和 filter (count 等于总作业数)，然后是副作用 Webhook 通知。对于 Wix 来说，使用现有的生产者 / 消费者基础设施更有意义，这对我们的微服务拓扑影响更小。
    

7 总结

这里的一些模式比其他的模式更为常见，但它们都有相同的原则。通过使用事件驱动的模式，可以减少样板代码（以及轮询和锁定原语），增加弹性（减少级联失败，处理更多的错误和边缘情况）。此外，微服务之间的耦合要小得多（生产者不需要知道谁消费了它的数据），扩展也更容易，向主题添加更多分区（和更多服务实例）即可。

**原文链接：**

https://medium.com/wix-engineering/6-event-driven-architecture-patterns-part-1-93758b253f47

https://medium.com/wix-engineering/6-event-driven-architecture-patterns-part-2-455cc73b22e1