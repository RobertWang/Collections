> 本文由 [简悦 SimpRead](http://ksria.com/simpread/) 转码， 原文地址 [mp.weixin.qq.com](https://mp.weixin.qq.com/s?__biz=MzAwNTAyMDY0MQ==&mid=2652614997&idx=1&sn=19aaa3ddc50ef4398c7fa3f834bc3546&chksm=80cc1fdbb7bb96cd8ad404f1f164494c411e3842484e9d0a1eb0c11afbecbac28cb4d511d430&scene=21#wechat_redirect)

插图: Paweł Jońca

科学发现理应是媒体的头版头条。但本期《自然》中，我们想要和读者一起**聊聊这些发现背后的故事，一起回顾过去几十年来极大地改变研究进程的关键代码。**

尽管这样的列表并非绝对，但在过去一年里我们调研了大量研究人员，汇总了不同领域内对科研带来巨大影响的的十大软件工具。

**编程语言先驱者：Fortran 编译器**

 **(1957)**

![图片](https://mmbiz.qpic.cn/sz_mmbiz_jpg/0OWoGbRW1icic7ZsgZ0aWLicVsZibPHcNYBicJJrZ6evuoL26p6h8vYqdsYYVwh0SmULd7Ctfw55gUiaL7ZbJXUIqxPA/640?wx_fmt=jpeg)

这台 CDC 3600 计算机于 1963 年送达位于科罗拉多州博尔德的国家大气研究中心，它可以在 Fortran 编译器的帮助下进行编程。来源：大气科学研究大学联盟 / Science Photo Library

但编程仍然不是一件容易的事情：早期的程序员使用打孔卡来输入代码，稍微复杂点的模拟就需要上万张打孔卡来编写程序。但新泽西普林斯顿大学的气候学家 Syukuro Manabe 表示，Fortran 为非计算机科学家的研究者提供了一种高效的编程手段。“我们第一次可以自己对计算机进行编程”，Manabe 说。他和同事们利用 Fortran 开发了第一个成功的气候模型。

如今，Fortran 已经进入了第八个十年，**它依旧广泛应用于气象建模、流体力学、计算化学和其他需要复杂线性代数与强大计算能力的学科。**其生成的代码运算高效，依然有很大比例的程序员会使用 Fortran。中古 Fortran 代码库仍然活跃在全球各地的超级计算机和实验室中。“以前的程序员清楚自己在做什么，” 加州蒙特雷海军研究生院的应用数学家和气候建模专家 Frank Giraldo 说，“他们非常注重内存，因为以前的内存非常小。”

**信号处理器：快速傅立叶变换**

 **(1965)**  

当射电天文学家扫视天空时，他们会捕获到一系列随时间变化的复杂信号。为了理解这些电波的本质，他们需要看到这些信号转成频率方程是什么样的。研究人员可以使用一种被称为傅立叶变换的数学过程来完成这一过程，问题在于它的效率很低，一个 _N_ 大小的数据集需要 _N_2 的计算量。

但在 1965 年，美国数学家 James Cooley 和 John Tukey 发明了一种方法来加速这一过程。**使用递归，一种 “分而治之” 的编程手段**（算法可以重复调用自身），**快速傅立叶变换**（FFT）**可以将傅立叶变换的计算降低到 _N_log2(_N_) 步**。计算速度随着数据集的增大而增加，1000 个数据点的情况下速度提升 100 倍，而对于一百万个点的情况则可以提速 5 万倍。

英国牛津大学的数学家 Nick Trefethen 说，这其实是一次重复发现——德国数学家高斯（Carl Friedrich Gauss）在 1805 年曾提出过这个算法，但他并未发表。然而，Cooley 和 Tukey **为数字信号处理、图像分析、结构生物学等等领域打开了广阔的应用空间。**Trefethen 说：“这确实是应用数学和工程领域的重大事件。” FFT 已经在代码中实现了很多次，最为著名的是 FFTW（西方最快的傅立叶变换）。

![图片](https://mmbiz.qpic.cn/sz_mmbiz_jpg/0OWoGbRW1icic7ZsgZ0aWLicVsZibPHcNYBic0oBNj8v6iaqjfGXicqZgzrPzaUWIV6P03iap623BV4ZuBYpZYNoZ3s1hg/640?wx_fmt=jpeg)

西澳大利亚无线电天文望远镜默奇森宽场阵列（Murchison Widefield Array）的夜景，该望远镜使用快速傅立叶变换收集数据。来源：John Goldsmith/Celestial Visions

加州劳伦斯伯克利国家实验室分子生物和集成生物成像部门的负责人 Paul Adams 回忆在 1995 年优化细菌蛋白 GroEL 结构时 [2]，即使使用了快速傅立叶变换和超级计算机，计算也耗费了大量的时间。他说：“如果没有 FFT，我甚至都不知道完成这些计算是否现实，可能会永远做不完。”

**分子编目：生物学数据库**

 **(1965)**  

数据库是当代科学研究不可或缺的部分，但人们很容易忽略它是由软件驱动的。在过去几十年里，这些资源得到了大规模的扩充，并改变了许多领域的研究方式，但或许没有哪个领域能像生物领域一样出现了翻天覆地的变化。

**当今大规模的基因和蛋白质数据库，源于马里兰国家生物研究基金会的生物信息学先驱 Margaret Dayhoff 的工作。**20 世纪 60 年代初，生物学家们致力于揭开蛋白质的氨基酸序列结构，Dayhoff 开始整理这些信息，寻找不同物种间演化关系的线索。她与三位合作者合著的《蛋白质序列和结构图集》（_Atlas of Protein Sequence and Structure_）于 1965 年首次发表，描述了当时已知的 65 种蛋白质序列、结构及其相似性。历史学家 Bruno Strasser 在 2010 年写道 [3]，**这个数据库是第一个不局限于具体研究问题的数据集。**Dayhoff 通过打卡纸带编码了这些数据，使得这一数据集具有可拓展和可搜索的潜力。

在这一研究后之后，其他的计算生物学数据库开始不断出现。于 1971 年诞生的蛋白质三维结构数据库（The Protein Data Bank）如今已经囊括了超过 17 万种大分子结构的详情。加州大学圣迭戈分校的演化生物学家 Russell Doolittle 于 1981 年创建了另一个名为 Newat 的蛋白质数据库。随后于 1982 年，诞生了后来的国际核酸序列数据库（GenBank），GenBank 的 DNA 档案是由美国国立卫生研究院（NIH）维护的。

![图片](https://mmbiz.qpic.cn/sz_mmbiz_jpg/0OWoGbRW1icic7ZsgZ0aWLicVsZibPHcNYBicMBaeQgPxLpatmtY6iaaVyGYJvzJ16HuMgHluFefJbbzhxH8g94g3yiag/640?wx_fmt=jpeg)

蛋白质数据银行中包含了超过 17 万种分子结构，包括这个结合 RNA 和蛋白质合成过程的细菌表达组。来源：David S. Goodsell and RCSB PDB (CC BY 4.0)

这些数据库在 1983 年 7 月证明了自己的巨大价值，当时由伦敦帝国癌症研究所的蛋白质生物化学家 Michael Waterfield 和 Doolittle 领导的两个团队，分别独立报告了一种人类特定生长因子与可使猴子患上癌症的病毒蛋白质序列间的相似性。观测结果**提出了一种通过模拟生长因子的病毒致癌机理，病毒可以诱导细胞不受调控地快速增生** [4]。美国国家生物信息研究中心（NCBI）前主任 James Ostell 认为：“这让生物学家们意识到，能利用计算机和统计学进行研究。通过比较蛋白质序列，我们能加深对癌症的理解。”

此外 Ostell 表示，**这一发现标志着 "客观生物学的问世"。**除了设计实验验证假设，研究人员还可以通过挖掘公开数据库，从中发现数据收集者可能从未想过的联系。随着越来越多的数据库被链接在一起，这一研究范式的巨大潜力急剧增长。NCBI 的程序员在 1991 年开发了一款可以在 DNA、蛋白质和文献中自由导航的工具 Entrez 实现了这一构想。

马里兰贝赛达 NCBI 的负责人 Stephen Sherry 曾在研究生阶段使用 Entrez，他说：“我还记得那时感觉像魔法一样神奇。”

**天气预报领导者：大气环流模式**

**(1969)**  

在二战结束时，计算机先驱冯 · 诺伊曼（John von Neumann）将战时用于计算弹道计算和武器设计的技术转向天气预报的研究。Manabe 说：“在那之前，天气预报都是依赖经验的，而冯 · 诺伊曼的团队则希望利用物理定律来实现数值天气预报。”

Venkatramani Balaji 是普林斯顿的美国国家海洋与大气管理局地球物理流体动力学实验室的建模系统负责人，他说，**描述这些过程的方程已经存在了几十年，但早期的气象学家不知道该如何解这些方程。**由于这些方程的计算需要给定当前条件，计算其在短期内随时间的变化，然后重复，这一过程十分耗时，而且计算的速度赶不上天气的变化。1922 年数学家 Lewis Fry Richardson 花费了几个月的时间计算了德国慕尼黑天气的 6 小时预报，但据记录来看预报的结果 “极不准确” ，还出现了“在任何已知陆面情况下都不可能发生” 的预测结果。计算机的出现让问题变得容易了许多。

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/0OWoGbRW1icic7ZsgZ0aWLicVsZibPHcNYBicmoRCqxymh6fWaDZMqIT0TicoqB25slHx8pm719ttJeYxABxSAic4s4RA/640?wx_fmt=png)

20 世纪 40 年代末，冯 · 诺伊曼在普林斯顿先进研究院建立了他的天气预报团队。第二支团队于 1955 年在地球物理流体动力学实验室展开对于 “无限预报”（气候模型）的研究工作。

Manabe 于 1958 年加入了气候建模团队致力于大气模型的研究。他的同事 Kirk Bryan 则专注于海洋。1969 年他们将两者成功结合起来，《自然》于 2006 称之为科学计算中的 “里程碑”。

如今的气象模型已经可以将地表划分为 25*25km 的区域，大气也被分为了几十个层次进行研究。当年 Manabe 和 Bryan 结合海洋 - 大气模型 [5] 使用的是 500 平方公里的区域和 9 个层次，并且只覆盖了 1/6 的地球表面。但 Balaji 依旧认为，“这一模型是一项伟大的工作”，使得团队第一次可以在计算机中模拟二氧化碳水平升高对气候的影响。

**数值计算加速器：BLAS**

**(1979)**  

科学计算通常利用向量和矩阵进行相对的简单数学运算，但计算量还是很大。而在上世纪 70 年代，科学界缺乏一套通用的计算工具来执行这些运算。**所以****科学界的程序员们要花时间编写完成基本数学运算的代码，而无法专心研究科学问题。**

但是编程世界需要一个标准。于是，1979 年，出现了基础线性代数程序集 (Basic Linear Algebra Subprograms, BLAS)[6]。这一标准一直发展到了 1990 年，为向量和后来的矩阵数学定义了一系列基本程序。

田纳西大学的计算机科学家 Jack Dongarra 认为，**BLAS 实际上将复杂的矩阵和向量运算简化成类似加减法一样基础的简单计算单元。**他是 BLAS 开发团队的一员。

![图片](https://mmbiz.qpic.cn/sz_mmbiz_jpg/0OWoGbRW1icic7ZsgZ0aWLicVsZibPHcNYBicOYmxA6RKHZLpdDmBbfKkZnKia0cprDXoCzDV3My30uRnX2icI13uoJjA/640?wx_fmt=jpeg)

Cray-1 超算：在 1979 年引入 BLAS 编程工具前，在加利福尼亚劳伦斯 · 利弗莫尔国家实验室里的 Cray-1 超级计算机等机器上工作的研究人员，没有线性代数标准。来源：Science History Images/Alamy

德克萨斯大学奥斯丁分校的计算机科学家 Robert van de Geijn 说，BLAS“可能是科学计算领域定义的最重要接口”。除了为常用函数提供标准命名，研究人员还可以确保基于 BLAS 的代码可以在任何计算机上以同样方式运行。这一标准同时也使得计算机产商可以不断优化 BLAS，好在他们的硬件上快速运行。

40 多年来，**BLAS 已经成为了科学计算技术栈的核心，使得科学计算软件得以持续发展。**乔治华盛顿大学的机械与航空工程师 Lorena Barba 将它称为 “代码五层结构内在的机制”。

Dongarra 说：“它是计算的基础结构。”

**必不可少的显微镜：NIH Image**

**(1987)**  

在上世纪 80 年代早期，程序员 Wayne Rasband 曾在马里兰贝塞斯达的美国国立卫生研究院（NIH）脑成像实验室工作。**其团队有一个可以对 X 光胶片进行数字化处理，但没办法在计算机上分析和显示。**Rasband 编写了一个程序来实现这一功能。

该程序是专门针对价值 15 万美元的 PDP-11 微型计算机设计的（安装在机架上的、绝不是个人用的那种电脑）。随后在 1987 年，苹果发行了操作更友好价格更实惠的 Macintosh II。Rasban 说：“我觉得这显然是更好的实验室图像分析系统。” 于是他将软件转移到了新的平台上（Macintosh II）并重新命名，从而引领了图像分析生态系统的发展.

NIH Image 及其后继者可以让研究人员在任何计算机上查看和量化任何图像。这一软件家族包含了 Rasband 为 Windows 和 Linux 用户写的 Java 版本软件 ImageJ；还有 Fiji，德国马克斯 · 普朗克研究所分子细胞生物学和遗传研究所 Pavel Tomancak 开发的、包含关键插件的 ImageJ。在麻省 Broad 研究所成像平台工作的计算生物学家 Beth Cimini 说：“ImageJ 无疑是我们拥有最基础的软件工具，我还从未见过哪个要用显微镜的生物学家不用 ImageJ 或者 Fiji 的。”

![图片](https://mmbiz.qpic.cn/sz_mmbiz_jpg/0OWoGbRW1icic7ZsgZ0aWLicVsZibPHcNYBicbrLYo79viaQ7zvgHXMjia2Ogs55v7libf2NbQibU2kI7GW7uda0h4qwnyg/640?wx_fmt=jpeg)

借助插件 ImageJ 工具可以自动识别显微图像中的细胞核。来源：Ignacio Arganda-Carreras/ImageJ

Rasband 认为部分原因是这些工具是免费的，但威斯康辛大学的生物医学工程师 Kevin Eliceiri 认为，更重要的是它们让用户能够简单根据自己需求定制工具，他的团队在 Rasband 退休后领导着 ImageJ 的研发。**ImageJ 具有极简的用户界面，自九十年代以来就没有太大的改变。**但这一工具却由于内置宏记录器（允许用户保存鼠标点击和菜单选择的操作序列来记录工作流）、强大的文件格式兼容性和灵活的插件架构而拥有了几乎无限的拓展性。Eliceiri 团队中的编程负责人 Curtis Rueden 说，有数百人在上传插件。**这些不断增加的插件极大地拓展了研究人员可用的工具集，包括从跟踪视频中的对象到自动识别细胞等丰富的功能。**

“这一软件的目的不是成为一切或者终结一切，而是服务于用户。”Eliceiri 说，“与其他程序不同，ImageJ 可以是用户想要的任何模样。”

**序列检索器：BLAST**

**(1990)**  

一个软件名从名词变成动词，这真是恰如其分地说明了其文化重要性。在搜索界有 Google，而对于基因领域来说，人们则会想起 BLAST。

演化变化以替代、敲除、空缺和重排等形式刻在分子序列上。通过搜索序列（特别是蛋白质）之间的相似结构，研究人员能发现其间的演化关系，更深入理解基因的功能。**实现这一想法的关键在于，在迅速膨胀的分子信息数据库中进行快速和全面的分析。**

1978 年 Dayhoff 为这个拼图补上了关键的一块。她提出了一种称为 "可接受点突变" 矩阵（PAM 矩阵）的描述方法，**使得研究人员可以通过序列间的相似性和演化距离来为两种蛋白质的相关性打分。**

1985 年，弗吉尼亚大学的 William Pearson 和 NCBI 的 David Lipman，在 Dayhoff 矩阵思想的基础上提出了一种更为高速的算法 FASTP。

几年后，Lipman 与 NCBI 的 Warren Gish 和 Stephen Altschul，宾夕法尼亚州立大学的 Webb Miller 和亚利桑那大学的 Gene Myers 共同研发了更为强大的版本：BLAST（the Basic Local Alignment Search Tool）。在 1990 年发布时，**BLAST 结合了可处理迅速增长数据库的快速搜索，和识别到较远演化距离的匹配的能力。**与此同时，它还可以计算出这些匹配有多大可能性是偶然发生的。

Altschul 说结果惊人地快：“只需要抿一口咖啡的时间就能完成复杂的搜索！” 但更重要的是这一工具很易用。在通过邮件更新数据库的时代，Gish 建立了电邮更新系统，并在后来构建了基于网络的架构，使得用户可以远程接入 NCBI 的计算机进行搜索，保证了数据的实时性。

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/0OWoGbRW1ic9GQFLb5FjZOvNrCEbpBCKdExRprlvN8NZRibnRHibW3O3azRR1zYRqjiaWB9w5HWIMJBPTfOsPy1bmw/640?wx_fmt=png)

上图中将数据制成表格并可视化的代码可以在 github 上获取：https://github.com/jperkel/nature_code_survey

哈佛大学计算生物学家 Sean Eddy 认为，这一系统为当时处于萌芽状态的基因组生物学提供了变革性的工具，通过相关基因的特性来研究未知基因的特性。对于世界各地的基因测序实验室，它提供了一个新词：“这就是那种会流变成一个动词的名词，”Eddy 说，“你会说**你正在 Blasting 自己的序列。**”

**预印本发电厂：arXiv.org**

**(1991)**  

上世纪 80 年代末期高能物理学家通常会将论文副本寄给同行，征询意见，同时也是一种礼节——不过仅发给少数几个人。“学术圈层级较低的人们，会仰赖科研名流们的恩惠，而富有才华和抱负却不在精英机构中的研究人员却常常被排除在外”，物理学家 Paul Ginsparg 在 2011 年写道 [7]。

1991 年，在新墨西哥州洛斯阿莫斯实验室工作的 Ginsparg 编写了一个电子邮件自动回复系统以推动这一领域的公平发展。订阅者将会收到每日的预印本论文，每篇文章都会被分配一个固定的文章识别号。**只需要一封邮件，世界范围内的用户都可以从实验室计算机系统提交或收到论文、获取最新论文的清单，或通过标题和作者进行搜索。**

Ginsparg 最早希望将文章保存 3 个月，而且仅限于高能物理领域。但在同事的劝说下，开始无限期保存文章。他说：“那是从电子公告栏过度到数据库存档的关键时刻。” 随后，这一系统的发展远远超出 Ginsparg 自己的学科，他在 1993 年将这一系统迁移到广域网上，并于 1998 年将域名修改为如今的 arXiv.org.

如今三十年过去了，**arXiv 已经累计保存了超过一百八十万篇预印本论文，并且全部免费开放。**同时每个月吸引一万五千次提交和超过三千万次下载。《自然 - 光子学》的编辑在十年前 [8] 网站成立 20 周年之际写到：“不难看出 arXiv 为何如此受欢迎，**这一系统为研究人员提供了便捷的方式来标记他们的工作和发现时间，避免了传统同行评议过程所需的事务和时长。**”

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/0OWoGbRW1icic7ZsgZ0aWLicVsZibPHcNYBicHqh3QjZCoJnYEQglA0iarPHRTTzEMeEUJ6T46GktEOMQALltkic0gAVg/640?wx_fmt=png)

来源: arXiv.org

该网站的成功促进了包括生物、医学、社会科学和其他姊妹领域预印本网站的蓬勃发展，到今天，从 SARS-CoV-2 病毒研究已发布的数万篇预印本论文中，可见其影响力。

Ginsparg 说：“30 年前这种方法在粒子物理学界以外还被视为异途，很高兴看到人们现在已经把它视作寻常。从这个角度来说，它就像一个成功的科研项目。”

**数据探索利器：IPython Notebook**

 **(2011)**

2001 年，当 Fernando Pérez 还是 “寻找拖延症” 课题的研究生时，他决定着手开发一个 Python 的核心组件。

**Python 是一种解释型语言，这意味着它需要逐行执行。**程序员通常使用一种称为 REPL（read–evaluate–print loop，一种交互式编程环境）的计算机调用 - 响应工具来编程，并使用解释器执行代码。REPL 可以用于迅速的探索和迭代开发，但 Pérez 认为 Python 并不是为科学构建的语言，比如说不能便捷地加载代码块或保持数据可视化开发。所以他写了自己的版本。

这造就了 IPython，一款 “交互式”Python 解释器。Pérez 于 2001 年 12 月发布了这一共 259 行的版本。十年后，Pérez 与物理学家 Brian Granger、数学家 Evan Patterson 合作，将这一工具移植到了浏览器中，开发出了 IPython Notebook，掀起了数据科学的革命浪潮。

与其他计算笔记本一样，IPython Notebook 在单个文件中融合了代码、结果、图形界面和文本内容。但与其他项目不同的是，IPython Notebook **是开源的，广大开发者社区都能对其做出贡献。**同时它还支持科学家们常用的语言 Python。在 2014 年，这一项目演变成了 Jupyter，**支持超过一百种语言，并允许用户在远程超级计算机上像使用自己电脑一般便捷地探索数据进行分析。**

“对于数据科学家来说，Jupyter 已经成为了实际的标准。” 《自然》2018 年写道 [9]。那时在代码共享平台 GitHub 上已经有超过 250 万份 Jupyter 笔记本了。如今则将近 1000 万份，包括 2016 年发现引力波和 2019 年为黑洞成像的代码。“我们为这一项目作出的微小工作为带来了巨大的回报。”Pérez 说。

**高速学习机：AlexNet**

**(2012)**  

一直以来人工智能（AI）存在两种不同的实现形式。**一种使用编码规则，而另一种则使用计算机通过模拟大脑的神经结构去 “学习”。**加拿大多伦多大学的计算机科学家 Geoffrey Hinton 说，几十年来 AI 研究者们都认为后一种方法是 “无稽之谈”。直到 2012 年，Hinton 的研究生 Alex Krizhevsky 和 Ilya Sutskever 在证明了并非如此。

ImageNet 是一项年度竞赛，研究人员们需要在一百万张日常对象的数据集上训练 AI，并在另一个独立的图像数据集上进行测试。当时，最好的算法会识别错大概 1/4 的图像，Hinton 说。Krizhevsky 和 Sutskever 提出的 AlexNet 是一种**基于神经网络的 “深度学习” 算法，将错误降低到了 16%**[10]。“我们基本上将错误率减半，几乎有一半。”Hinton 补充道。

Hinton 认为其团队在 2012 年的成功反映了足够大的训练数据集、优秀的编程和新出现强大算力 GPU（一种最早设计用于加速计算机视频性能的处理器）的结合迸发出的强大潜力。“突然之间，我们可以以 30 倍的速度运行算法，” 他说，“或者在 30 倍的数据上进行学习。”

Hinton 说，算法上真正的突破其实在三年前就已经实现，当时他实验室创造的神经网络已经可以实现比经过几十年优化的传统 AI 更为精确的语音识别了。“虽然只（比传统 AI）好了一点点，”Hinton 说，“但这已经预兆了未来。”

**这些成果预示着深度学习在实验室、工业界的崛起。**这就是为什么手机可以理解语音查询、图像分析工具可以迅速从光学显微镜图像中挑选出细胞。同时这也是 AlexNet 可以从根本上改变科学，并与众多重要的计算机工具改变世界的原因所在。

参考文献：

1. The Event Horizon Telescope Collaboration _et al. Astrophys. J. Lett._ **875**, L1 (2019).

2. Braig, K., Adams, P. D. & Brünger, A. T. _Nature Struct. Biol._**2**, 1083–1094 (1995).

3. Strasser, B. J. _J. Hist. Biol._**43**, 623–660 (2010).

4. Newmark, P. _Nature_ **304**, 108 (1983).

5. Manabe, S. & Bryan, K. _J. Atmos. Sci_. **26**, 786–789 (1969).

6. Lawson, C. L., Hanson, R. J., Kincaid, D. R. & Krogh, F. T. _ACM Trans. Math. Software_**5**, 308–323 (1979).

7. Ginsparg, P. Preprint at http://arxiv.org/abs/1108.2700 (2011).

8. _Nature Photon_. **6**, 1 (2012).

9. _Nature_ **563**, 145–146 (2018).

10. Krizhevsky, A., Sutskever, I. & Hinton, G. E. in _Proc. 25th Int. Conf. Neural Information Processing Systems_ (eds Pereira, F., Burges, C. J. C., Bottou, L. & Weinberger, K. O.) 1097–1105 (Curran Associates, 2012).

_原文以_ _Ten computer codes that transformed science 标题发表在 2021 年 1 月 20 日的《自然》的新闻特写__版块上_

**© nature**

**doi: 10.1038/d41586-021-00075-2**

点击**阅读原文**查看英文原文

**点击文字或图片阅读相关文章**

版权声明：  

本文由施普林格 · 自然上海办公室负责翻译。中文内容仅供参考，一切内容以英文原版为准。欢迎转发至朋友圈，如需转载，请邮件 China@nature.com。未经授权的翻译是侵权行为，版权方将保留追究法律责任的权利。

© 2021 Springer Nature Limited. All Rights Reserved