> 本文由 [简悦 SimpRead](http://ksria.com/simpread/) 转码， 原文地址 [mp.weixin.qq.com](https://mp.weixin.qq.com/s?__biz=MjM5OTA1MDUyMA==&mid=2655469399&idx=1&sn=e6d1ab2f12b5647e2341f055c948cadb&chksm=bd72f3208a057a36233045d40e5290fc2b17e3beb540ac9a253419172ce101a7338cb31d3ad5&scene=21#wechat_redirect)

今天分享一个「多模态」算法 **NÜWA**（女娲）。  

![](https://mmbiz.qpic.cn/mmbiz_png/v1JN0W4OpXjKxdrh3FDZeCbe2ZnbF12XsibPUbA9Vm0TZSRRLcq3icdgJ4oBibvy71nKz5W8ia5FWCMG8GQ7eR1TIA/640?wx_fmt=png)

8 项典型的视觉生成任务

碾压各种对比的算法效果，**杀疯了！**  

NÜWA 效果
-------

我们先看下 **NÜWA** 这算法在 8 项经典的视觉生成任务中的表现。

### Text-To-Image(T2I)

文字转图片任务，其实就是根据一段文字描述，生成对应描述的图片。

**比如：**

`A dog with gogglesstaring at the camera.`

一只戴着护目镜，盯着摄像机的狗。

![](https://mmbiz.qpic.cn/mmbiz_png/v1JN0W4OpXjKxdrh3FDZeCbe2ZnbF12XbKrTnE4GIzzJdVC3bDVxuXSibWsLDjrEicqNsI4kIuYGia9ciac9sYxjmA/640?wx_fmt=png)

还有更多效果：

![](https://mmbiz.qpic.cn/mmbiz_png/v1JN0W4OpXjKxdrh3FDZeCbe2ZnbF12XrATejHntuynRn9icE1Xibx3B80TibmibERNlTByStzYEOiciaJ48sPtCfxxA/640?wx_fmt=png)

**NÜWA** 生成的效果看起来就没那么违和，从论文的效果看，很真实！

![](https://mmbiz.qpic.cn/mmbiz_png/v1JN0W4OpXjKxdrh3FDZeCbe2ZnbF12XqpBiac1a7HxhiajaPQXtic7GiaelhSiaqXVEqUTL29vicL8xTOLJHvuCyViaQ/640?wx_fmt=png)

效果非常 Amazing。

### Sketch-To-Image (S2I)

草图转图片任务，就是根据草图的布局，生成对应的图片。

![](https://mmbiz.qpic.cn/mmbiz_png/v1JN0W4OpXjKxdrh3FDZeCbe2ZnbF12XqOpCflrVpX32H0DC7ytW3hFssKoyOTiamIBrwmEfNP7FF9FuUZ5zkFg/640?wx_fmt=png)

**比如：**

在一张图片上，画个大致轮廓，就可以自动 “脑补” 图片。

![](https://mmbiz.qpic.cn/mmbiz_png/v1JN0W4OpXjKxdrh3FDZeCbe2ZnbF12XATSibatIYU17yicPEJX5Jv5ezMD30DC6n2ZTfvng8fc4F4hnEfB6fsoA/640?wx_fmt=png)

这效果真是开了眼了，真实效果真如论文这般的话，那确实很强。

![](https://mmbiz.qpic.cn/mmbiz_png/v1JN0W4OpXjKxdrh3FDZeCbe2ZnbF12XeZ0qBuh4Q9ISwWn9yTeaV1gN4HSBvncialia76Y10ScHcNgZUBKSUoKQ/640?wx_fmt=png)

**这个算法，可以用在很多有意思的场景。**

### Image Completion (I2I)

图像补全，如果一副图片残缺了，算法可以自动 “脑补” 出残缺的部分。

![](https://mmbiz.qpic.cn/mmbiz_png/v1JN0W4OpXjKxdrh3FDZeCbe2ZnbF12XlIVYtkSU0eG46OKEDUqBicNbOCpicP9BrGF0BgPXHGEibwKYLyxicCDp8Q/640?wx_fmt=png)

好家伙，**是不是又有一些大胆的想法了？**

![](https://mmbiz.qpic.cn/mmbiz_png/v1JN0W4OpXjKxdrh3FDZeCbe2ZnbF12X4hgU1icoxe62KqIqgnvTlzXicAw9SjVWibWwaibVY68YNJLiah4zgGKN0Fg/640?wx_fmt=png)

这个遮挡还算可以，还有更细碎的。

![](https://mmbiz.qpic.cn/mmbiz_png/v1JN0W4OpXjKxdrh3FDZeCbe2ZnbF12Xk1rn1DibiasGMa0ST92qMHeBFicGibXZkBYIiaMic8zguxAj7OB0garPPFLA/640?wx_fmt=png)

图片碎成这样，还能 “脑补” 出画面，我很期待代码。

### Image Manipulation (TI2I)

图片处理，根据文字描述，处理图片。

比如：

有一副草原的图片，然后增加一段描述：

`a horse is running on the grassland`

一匹马奔跑在草原上，然后就可以生成对应的图片。

![](https://mmbiz.qpic.cn/mmbiz_png/v1JN0W4OpXjKxdrh3FDZeCbe2ZnbF12XNT9J7gzEcbWPe516KXrzF11xa7QmPpungZPvKnvGbpj7lT5sbNXabA/640?wx_fmt=png)

这惊人的理解力。

![](https://mmbiz.qpic.cn/mmbiz_png/v1JN0W4OpXjKxdrh3FDZeCbe2ZnbF12X48tIAibf9Hs0RB4ktHFJjyvd2toW9icfjnqNiaORproRGDbticU1KJfgiaw/640?wx_fmt=png)

这让我想起来了 P 图吧大神，恶搞的作品。

![](https://mmbiz.qpic.cn/mmbiz_png/v1JN0W4OpXjKxdrh3FDZeCbe2ZnbF12XQsV4d4R58RrHddk5m2Nj33TxBGI2Awq117UPQwhJuialvfOPQDpd58w/640?wx_fmt=png)

有了这个算法，咱也可以试一试了，哈哈。

### Video

这还不算完，除了上述的生成图片的**四种**效果，**NÜWA** 还可以生成视频！

![](https://mmbiz.qpic.cn/mmbiz_png/v1JN0W4OpXjKxdrh3FDZeCbe2ZnbF12Xqh9AuzYOibOGwIrWpH7WWicTYlkNjzClOkQHwPvTQUwlV9LKP6lvauXg/640?wx_fmt=png)

对应的四种视频生成任务：

*   Text-To-Video (T2V)
    
*   Sketch-To-Video (S2V)
    
*   Sketch-To-Video (S2V)
    
*   Video Manipulation (TV2V)
    

既可以玩图片又可以玩视频。

![](https://mmbiz.qpic.cn/mmbiz_gif/v1JN0W4OpXjKxdrh3FDZeCbe2ZnbF12XXHx3eMHZWkhtTOIdOf5uvgWQxnCYkHyvTOUlrnBNN30lPEFHn2kGOg/640?wx_fmt=gif)

NÜWA 原理
-------

NÜWA 模型的整体架构包含一个支持多种条件的 adaptive 编码器和一个预训练的解码器，能够同时使图像和视频的信息。

对于图像补全、视频预测、图像处理和视频处理任务，将输入的部分图像或视频直接送入解码器即可。

![](https://mmbiz.qpic.cn/mmbiz_png/v1JN0W4OpXjKxdrh3FDZeCbe2ZnbF12X9hhAPVWLgJbxfDsQYibLiaeX0IQeWeAicR34iac4bib8JWlf5Q8Gqo9EichQ/640?wx_fmt=png)

而编码解码器都是基于一个 3D Nearby 的自注意力机制（3DNA）建立的，该机制可以同时考虑空间和时间轴的上局部特性，定义如下：

![](https://mmbiz.qpic.cn/mmbiz_png/v1JN0W4OpXjKxdrh3FDZeCbe2ZnbF12XlZhPeoevMYJRPibeRMv1yGINCrIzOJkcjWcqEjeaeW6GHRKVdBkaricg/640?wx_fmt=png)

W 表示可学习的权重，X 和 C 分别代表文本、图像、视频数据的 3D 表示。

3DNA 考虑了完整的邻近信息，并为每个 token 动态生成三维邻近注意块。注意力矩阵还显示出 3DNA 的关注部分（蓝色）比三维块稀疏注意力和三维轴稀疏注意力更平滑。

![](https://mmbiz.qpic.cn/mmbiz_png/v1JN0W4OpXjKxdrh3FDZeCbe2ZnbF12Xxbv54cSnOnpIeQPZ9u3EO8iamT5iaw6T0woRgDyUkxJtZGsws8uIIv3Q/640?wx_fmt=png)

更多细节，可以直接看论文：

> 论文地址：
> 
> https://arxiv.org/abs/2111.12417

NÜWA 代码
-------

NÜWA 的代码还没有开源，不过 Github 已经建立。

> Github:
> 
> https://github.com/microsoft/NUWA

作者表示，很快就会开源：

![](https://mmbiz.qpic.cn/mmbiz_png/v1JN0W4OpXjKxdrh3FDZeCbe2ZnbF12Xr1ZOBKYO3swwLAsZKErDcQeTybUxdicNzny9CdVtxvD131VZHW6ZeGg/640?wx_fmt=png)

公司有开源审批流程，代码也得梳理下，所以可以先 Star 上标记下，耐心等等。

**微软亚研院和北大**联合打造的一个多模态预训练模型 NÜWA，在首届微软峰会上亮相过。

这种应该不会鸽的~

总结
--

今年算是多模态 Transformer 大力发展的一年，从各种顶会的论文就能看出，各种多模态。

- EOF -