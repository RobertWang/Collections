> 本文由 [简悦 SimpRead](http://ksria.com/simpread/) 转码， 原文地址 [mp.weixin.qq.com](https://mp.weixin.qq.com/s?__biz=MzA4MjEyNTA5Mw==&mid=2652592262&idx=2&sn=f79265b06f7957d942a2da8623481c33&chksm=846570ccb312f9daa266883d9bfea3ceb1d9243eb24480887e8fbce8f4353f36173b3380c281&mpshare=1&scene=1&srcid=0403eT57latEztOtewXX1M1M&sharer_sharetime=1648982071556&sharer_shareid=8a467675e94cd5b11b6640b7770d6cc6#rd)

一、推荐的技术方法


-------------

推荐系统简单来说就是， 高效地达成用户与意向对象的匹配。具体可见之前文章：[【一窥推荐系统的原理】](http://mp.weixin.qq.com/s?__biz=MzA4MjEyNTA5Mw==&mid=2652591856&idx=2&sn=9e5d503c6550217b12e2a6c7bc5b57de&chksm=84657ebab312f7acf2e2ac1e96d99765e1b085081f595c8263a6b431ae86e3bbd5e286441673&scene=21#wechat_redirect)。而技术上实现两者匹配，简单来说有两类方法：

### 1.1 基于分类方法

分类的方法很好理解，预测用户对该类别是否有偏好。

*   可以训练一个意向物品的多分类模型，预测用户偏好哪一类物品。
    
*   或者将用户 + 物品等全方面特征作为拼接训练二分类模型，预测为是否偏好（如下经典的 CTR 模型，以用户物品特征及对应的标签 0 或 1 构建分类模型，预测该用户是否会点击这物品，）。![](https://mmbiz.qpic.cn/mmbiz_png/eyibF6kJBjTv9M0fOrNocvCBL2I5rHO5tgaXuWontdJo7q4icTV79cokibALwnxdK9NcCxuUtuIiaqaIPEL1COMfeA/640?wx_fmt=png)
    

基于分类的方法，精度较高，常用于推荐的排序阶段（如粗排、精排）。

### 1.2 基于相似度方法

利用计算物与物或人与人、人与物的距离，将物品推荐给喜好相似的人。

*   如关联规则推荐，可以将物与物共现度看做为某种的相似度；
    
*   协同过滤算法可以基于物品或者基于用户计算相似用户或物品；
    
*   以及本文谈到的**双塔模型**，是通过计算物品与用户之间的相似度距离并做推荐。![](https://mmbiz.qpic.cn/mmbiz_png/eyibF6kJBjTv9M0fOrNocvCBL2I5rHO5toJiam1HpamDHUH6ynrFOmFX4adoiauxILf8yicdp6Hc26z9jzCj07hwSQ/640?wx_fmt=png)
    

利用相似度的方法效率快、准确度差一些常用于推荐中的粗排、召回阶段。

2. DSSM 双塔模型
------------

### 2.1 DSSM 模型的原理

DSSM(Deep Structured Semantic Models) 也叫深度语义匹配模型，最早是微软发表的一篇应用于 NLP 领域中计算语义相似度任务的文章。

DSSM 深度语义匹配模型原理很简单：获取搜索引擎中的用户搜索 query 和 doc 的海量曝光和点击日志数据，训练阶段分别用复杂的深度学习网络构建 query 侧特征的 query embedding 和 doc 侧特征的 doc embedding，线上 infer 时通过计算两个语义向量的 cos 距离来表示语义相似度，最终获得语义相似模型。这个模型既可以获得语句的低维语义向量表达 sentence embedding，还可以预测两句话的语义相似度。

### 2.2 DSSM 模型结构

DSSM 模型总的来说可以分成三层结构，分别是输入层、表示层和匹配层。

*   输入层 将用户、物品的信息转化为数值特征输入；
    
*   表示层 进一步用神经网络模型学习特征表示；
    
*   匹配层 计算用户特征向量与物品特征向量的相似度；
    

结构如下图所示：![](https://mmbiz.qpic.cn/mmbiz_png/eyibF6kJBjTv9M0fOrNocvCBL2I5rHO5tRLTvKEQhWBQyLRhYY4APicVj4q2MUsuQtl0ZaXTO9ucvPdQR7E7libkg/640?wx_fmt=png)

3. 双塔模型代码实践
-----------

*   读取电影数据集（用户信息、电影信息、评分行为信息），数据格式处理、特征序列编码、数据拼接, 并做评分的归一化处理作为模型学习的相似度目标（注：这里也可以另一个思路对评分做阈值划分，按照一个分类任务来解决）
    

```
import pandas as pdimport numpy as npimport tensorflow as tffrom tensorflow import kerasfrom tensorflow.keras import layersimport matplotlib.pyplot as plt### 1. 读取电影数据集（用户信息、电影信息、评分行为信息）df_user = pd.read_csv("./ml-1m/users.dat",                     sep="::", header=None, engine="python",encoding='iso-8859-1',                     names = "UserID::Gender::Age::Occupation::Zip-code".split("::"))df_movie = pd.read_csv("./ml-1m/movies.dat",                     sep="::", header=None, engine="python",encoding='iso-8859-1',                     names = "MovieID::Title::Genres".split("::"))df_rating = pd.read_csv("./ml-1m/ratings.dat",                     sep="::", header=None, engine="python",encoding='iso-8859-1',                     names = "UserID::MovieID::Rating::Timestamp".split("::"))import collections# 计算电影中每个题材的次数genre_count = collections.defaultdict(int)for genres in df_movie["Genres"].str.split("|"):    for genre in genres:        genre_count[genre] += 1genre_count# # 每个电影只保留频率最高（代表性）的电影题材标签def get_highrate_genre(x):    sub_values = {}    for genre in x.split("|"):        sub_values[genre] = genre_count[genre]    return sorted(sub_values.items(), key=lambda x:x[1], reverse=True)[0][0]df_movie["Genres"] = df_movie["Genres"].map(get_highrate_genre)df_movie.head()# #### 给特征列做序列编码def add_index_column(param_df, column_name):    values = list(param_df[column_name].unique())    value_index_dict = {value:idx for idx,value in enumerate(values)}    param_df[f"{column_name}_idx"] = param_df[column_name].map(value_index_dict)add_index_column(df_user, "UserID")add_index_column(df_user, "Gender")add_index_column(df_user, "Age")add_index_column(df_user, "Occupation")add_index_column(df_movie, "MovieID")add_index_column(df_movie, "Genres")# 合并成一个dfdf = pd.merge(pd.merge(df_rating, df_user), df_movie)df.drop(columns=["Timestamp", "Zip-code", "Title"], inplace=True)num_users = df["UserID_idx"].max() + 1num_movies = df["MovieID_idx"].max() + 1num_genders = df["Gender_idx"].max() + 1num_ages = df["Age_idx"].max() + 1num_occupations = df["Occupation_idx"].max() + 1num_genres = df["Genres_idx"].max() + 1num_users, num_movies, num_genders, num_ages, num_occupations, num_genres# #### 评分的归一化min_rating = df["Rating"].min()max_rating = df["Rating"].max()df["Rating"] = df["Rating"].map(lambda x : (x-min_rating)/(max_rating-min_rating)) # 评分作为两者的相似度# df["is_rating_high"] = (df["Rating"]>=4).astype(int)  # 可生成是否高评分作为分类模型的类别标签df.sample(frac=1).head(3)# 构建训练集特征及标签df_sample = df.sample(frac=0.1)  # 训练集抽样X = df_sample[["UserID_idx","Gender_idx","Age_idx","Occupation_idx","MovieID_idx","Genres_idx"]]y = df_sample["Rating"]
```

![](https://mmbiz.qpic.cn/mmbiz_png/eyibF6kJBjTv9M0fOrNocvCBL2I5rHO5tR05QHLN9IKs2QJupSkTebAlFua6icdqcVANzG0ta0gwq0TDqFvGOhrQ/640?wx_fmt=png)

*   构建双塔模型，训练预测用户 / 产品间的相似度。进一步可以提取用户、产品的特征表示方便后续直接结算相似度。![](https://mmbiz.qpic.cn/mmbiz_png/eyibF6kJBjTv9M0fOrNocvCBL2I5rHO5ttGyNHOblmib3wEYK62lZIZZnLBpCKYmX7Wd4C3RHKTb3MicPROHaic8nA/640?wx_fmt=png)
    

```
def get_model():    """搭建双塔DNN模型"""        # 输入    user_id = keras.layers.Input(shape=(1,), )        # user 塔    user_vector = tf.keras.layers.concatenate([            layers.Embedding(num_users, 100)(user_id),             layers.Embedding(num_genders, 2)(gender),             layers.Embedding(num_ages, 2)(age),             layers.Embedding(num_occupations, 2)(occupation)    ])    user_vector = layers.Dense(32, activation='relu')(user_vector)    user_vector = layers.Dense(8, activation='relu',                                , kernel_regularizer='l2')(user_vector)    # item 塔    movie_vector = tf.keras.layers.concatenate([        layers.Embedding(num_movies, 100)(movie_id),        layers.Embedding(num_genres, 2)(genre)    ])    movie_vector = layers.Dense(32, activation='relu')(movie_vector)    movie_vector = layers.Dense(8, activation='relu',                                 , kernel_regularizer='l2')(movie_vector)    # 每个用户的embedding和item的embedding作点积    dot_user_movie = tf.reduce_sum(user_vector*movie_vector, axis = 1)    dot_user_movie = tf.expand_dims(dot_user_movie, 1)    output = layers.Dense(1, activation='sigmoid')(dot_user_movie)        return keras.models.Model(inputs=[user_id, gender, age, occupation, movie_id, genre], outputs=[output]) model = get_model()model.compile(loss=tf.keras.losses.MeanSquaredError(),               optimizer=keras.optimizers.RMSprop())fit_x_train = [        X["UserID_idx"],         X["Gender_idx"],        X["Age_idx"],        X["Occupation_idx"],        X["MovieID_idx"],        X["Genres_idx"]    ]history = model.fit(    x=fit_x_train,    y=y,    batch_size=32,    epochs=5,    verbose=1)# ### 3. 模型的预估-predict# 输入前5个样本并做预测inputs = df[["UserID_idx","Gender_idx","Age_idx","Occupation_idx","MovieID_idx", "Genres_idx"]].head(5)display(df.head(5))# 对于（用户ID，召回的电影ID列表），计算相似度分数model.predict([        inputs["UserID_idx"],         inputs["Gender_idx"],        inputs["Age_idx"],        inputs["Occupation_idx"],        inputs["MovieID_idx"],        inputs["Genres_idx"]    ])# 可以提取模型中的user或movie item 的embeddinguser_layer_model = keras.models.Model(    inputs=[model.input[0], model.input[1], model.input[2], model.input[3]],    outputs=model.get_layer("user_embedding").output)user_embeddings = []for index, row in df_user.iterrows():    user_id = row["UserID"]    user_input = [        np.reshape(row["UserID_idx"], [1,1]),        np.reshape(row["Gender_idx"], [1,1]),        np.reshape(row["Age_idx"], [1,1]),        np.reshape(row["Occupation_idx"], [1,1])    ]    user_embedding = user_layer_model(user_input)        embedding_str = ",".join([str(x) for x in user_embedding.numpy().flatten()])    user_embeddings.append([user_id, embedding_str])df_user_embedding = pd.DataFrame(user_embeddings, columns = ["user_id", "user_embedding"])df_user_embedding.head()
```

*   输入前 5 个样本并做预测，计算用户与电影之间的相似度匹配的分数, 进一步就可以推荐给用户匹配度高的电影。
    

![](https://mmbiz.qpic.cn/mmbiz_png/eyibF6kJBjTv9M0fOrNocvCBL2I5rHO5tBPib5yicELUzZ71SjvmTdpFFlwSuWlaNxXHcibjwnSUINdWBZsSwEwjBQ/640?wx_fmt=png)

- EOF -