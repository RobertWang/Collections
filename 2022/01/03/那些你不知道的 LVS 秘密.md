> 本文由 [简悦 SimpRead](http://ksria.com/simpread/) 转码， 原文地址 [mp.weixin.qq.com](https://mp.weixin.qq.com/s/_nX5ZdBCpZ_4fzlI5zN_vA)

**一、什么是负载均衡**

负载平衡（Load balancing）是一种电子计算机技术，用来在多个计算机（计算机集群）、网络连接、CPU、磁盘驱动器或其他资源中分配负载，以达到优化资源使用、最大化吞吐率、最小化响应时间、同时避免过载的目的。使用带有负载平衡的多个服务器组件，取代单一的组件，可以通过冗余提高可靠性。负载平衡服务通常是由专用软件和硬件来完成。主要作用是将大量作业合理地分摊到多个操作单元上进行执行，用于解决互联网架构中的高并发和高可用的问题。

**二、为什么需要负载均衡**

实际生产环境中某单台服务器已不能负载日常用访问压力时，就需要使用负载均衡，把用户的请求数据分担到（尽可能平均分配）后端所有功能同等的集群的节点上, 同样也是为了解决单台服务器故障问题，从而提高用户的访问体验。

**三、负载均衡分类**

**3.1 DNS 负载均衡**

思路是 DNS 解析同一个域名时可以返回不同的 IP 地址。

用来实现地理级别的均衡，例如，北方用户访问北京机房、南方用户访问深圳机房。

优点：

简单，成本低，直接交给 DNS 服务器处理即可，无需自己维护。

就近访问，提升访问速度。

缺点：

DNS 缓存时间较长，更新不及时。

DNS 控制权在域名商那里，无法根据业务特点定制扩展。

**3.2  硬件负载均衡**

通过单独的硬件设备实现负载均衡，典型设备例如 F5、A10。

优点：

功能强大，支持各级负载均衡，支持各种负载均衡算法，支持全局负载均衡。

性能强大，可以支持 100 万以上的并发。

稳定性高。

支持安全防护，除了负载均衡的功能，还有防火墙、防 DDoS 攻击等安全功能。

缺点：

昂贵，价格几万甚至数十万。

扩展能力差。

**3.3  软件负载均衡**

通过软件实现，例如我们熟悉的 Nginx（7 层负载均衡） 和 LVS（4 层负载均衡）。

和硬件负载均衡相比，性能差了很多，Nginx 能支持 5 万 / 秒，而 F5 是百万级，但价格也便宜了很多。

优点：简单、灵活、便宜

缺点：相对于硬件负载均衡，性能一般

**四、LVS** **简单介绍**

LVS 是 Linux Virtual Server 的简写，意即 Linux 虚拟服务器，是一个虚拟的服务器集群系统。本项目在 1998 年 5 月由章文嵩博士成立，是中国国内最早出现的自由软件项目之一。目前 LVS 已经被集成到 Linux 内核模块中

官方网站：http://www.linuxvirtualserver.org/zh/  

**五、LVS** **的负载均衡结构图**

lvs 的负载均衡结构图，大概的使用场景如下

![](https://mmbiz.qpic.cn/mmbiz_jpg/h2xc1OKOGcl5HmficmiclXUGJeaG0aY7DgJxZB66TkFQHovf92L4eic6ibiaLsYYWlibtVWU8QicgnDR6Xcxzgj9ibGSFw/640?wx_fmt=jpeg)

**六、LVS** **相关术语介绍**

CIP 客户端的 IP 地址  
VIP LVS 负载均衡公网 IP 面向客户端的地址  
DIP LVS 负载均衡内网 IP 主要与后端的 RIP 进行通讯  
RIP 后端真实的 IP 地址

**七、LVS** **四种工作模式原理简介及优缺点分析**

**7.1  NAT 模式（LVS-NAT）**

![](https://mmbiz.qpic.cn/mmbiz_png/h2xc1OKOGcl5HmficmiclXUGJeaG0aY7DgHU8omezo9gFJREFgCGrlNmhMSSeFXMXIx7bYxHMmI490l7ZjOx8dJw/640?wx_fmt=png)

原理：把客户端发来的数据包在负载均衡器上将目的地址封装成其中一台 RS 的 IP 地址，并发至该 RS 来处理, RS 处理完成后把数据包发给负载均衡器, 负载均衡器再把数据包的原 IP 地址封装成为自己的 IP，将目的地址封装成客户端 IP 地址，然后发给客户端｡无论是进来的流量, 还是出去的流量, 都必须经过负载均衡器｡

优点：集群中的物理服务器可以使用任何支持 TCP/IP 的操作系统，只有负载均衡器需要一个合法的 IP 地址。

缺点：扩展性有限。当服务器节点（普通 PC 服务器）增长过多时, 负载均衡器将成为整个系统的瓶颈，因为所有的请求包和应答包的流向都经过负载均衡器。当服务器节点过多时，大量的数据包都交汇在负载均衡器那，速度就会变慢！

**7.2  LVS FULL NAT 模式**

![](https://mmbiz.qpic.cn/mmbiz_png/h2xc1OKOGcl5HmficmiclXUGJeaG0aY7Dg9oKMpFTgiaXCVNJNia7czOl1GWxKzSbIOYeIjha5iaqFiaVgTLEaSdVObw/640?wx_fmt=png)

原理：FULL NAT 在 client 请求 VIP 时，不仅替换了 package 的 dst ip，还替换了 package 的 src ip；但 VIP 返回给 client 时也替换了 src ip，具体分析如下：

首先 client 发送请求 [package] 给 VIP；VIP 收到 package 后，会根据 LVS 设置的 LB 算法选择一个合适的 realserver，然后把 package 的 DST IP 修改为 realserver；把 sorce ip 改成 lvs 集群的 LB IP ；realserver 收到这个 package 后判断 dst ip 是自己，就处理这个 package ，处理完后把这个包发送给 LVS VIP；LVS 收到这个 package 后把 sorce ip 改成 VIP 的 IP，dst ip 改成 client ip 然后发送给 client。

FULL NAT 模式也不需要 LBIP 和 realserver ip 在同一个网段；

full nat 因为要更新 sorce ip 所以性能正常比 nat 模式下降 10%

**7.3  IP 隧道模式（LVS-TUN）**

![](https://mmbiz.qpic.cn/mmbiz_png/h2xc1OKOGcl5HmficmiclXUGJeaG0aY7DgGyxSyhzze1zyNicIJF2kjwCFO186ZkEia6zG7icTmggTKXRAdWcbJWZSQ/640?wx_fmt=png)

原理：由于互联网上的大多 Internet 服务的请求包很短小，而应答包通常很庞大，使用 nat 模式庞大的应答数据包也必须经过负载均衡器，这就加重了负载均衡器的负担，隧道模式就是优化这个问题的。所以隧道模式就是，把客户端发来的数据包，封装一个新的 IP 头标记 (仅目的 IP) 发给 RS,RS 收到后, 先把数据包的头解开, 还原数据包, 处理后, 直接返回给客户端, 不需要再经过负载均衡器｡注意, 由于 RS 需要对负载均衡器发过来的数据包进行还原, 所以说必须支持 IPTUNNEL 协议｡所以, 在 RS 的内核中, 必须编译支持 IPTUNNEL 这个选项

优点：负载均衡器只负责将请求包分发给后端节点服务器，而 RS 将应答包直接发给用户。所以，减少了负载均衡器的大量数据流动，负载均衡器不再是系统的瓶颈，就能处理很巨大的请求量，这种方式，一台负载均衡器能够为很多 RS 进行分发。而且跑在公网上就能进行不同地域的分发。

缺点：隧道模式的 RS 节点需要合法 IP，这种方式需要所有的服务器支持”IP Tunneling”(IP Encapsulation) 协议，服务器可能只局限在部分 Linux 系统上。

**7.4  直接路由模式（LVS-DR）**

![](https://mmbiz.qpic.cn/mmbiz_png/h2xc1OKOGcl5HmficmiclXUGJeaG0aY7Dgv2PGib5OtHnkFRwg2O3uRuoPgIHWqg0Dpz4N3zkIDEanicpiaJsh8UFPA/640?wx_fmt=png)

原理：负载均衡器和 RS 都使用同一个 IP 对外服务｡但只有 DR 对 ARP 请求进行响应, 所有 RS 对本身这个 IP 的 ARP 请求保持静默｡也就是说, 网关会把对这个服务 IP 的请求全部定向给 DR, 而 DR 收到数据包后根据调度算法, 找出对应的 RS, 把目的 MAC 地址改为 RS 的 MAC（因为 IP 一致）并将请求分发给这台 RS｡这时 RS 收到这个数据包, 处理完成之后，由于 IP 一致，可以直接将数据返给客户，则等于直接从客户端收到这个数据包无异, 处理后直接返回给客户端｡由于负载均衡器要对二层包头进行改换, 所以负载均衡器和 RS 之间必须在一个广播域, 也可以简单的理解为在同一台交换机上｡

优点：和 TUN（隧道模式）一样，负载均衡器也只是分发请求，应答包通过单独的路由方法返回给客户端。与 VS-TUN 相比，VS-DR 这种实现方式不需要隧道结构，因此可以使用大多数操作系统做为物理服务器。

不足：要求负载均衡器的网卡必须与物理网卡在一个物理段上

**八、负载均衡调度算法简介**

LVS 有两种类型的调度算法，其一就是静态的调度算法，这种算法一经实现，后续就不会发生变化，是既定的规则，后续数据包的流转都会按照这种规则进行按部就班的流转；其二就是动态的调度算法，这种算法是基于网络状况，或者后端服务器的状况，连接的状况等来进行实时的调整，算法的规则会根据实际情况而发生一定的变化。

常用的静态调度算法有以下几种：

1） RR：轮叫调度（Round Robin）  
调度器通过” 轮叫” 调度算法将外部请求按顺序轮流分配到集群中的真实服务器上，它均等地对待每一台服务器，而不管服务器上实际的连接数和系统负载｡

2） WRR：加权轮叫（Weight RR）  
调度器通过 “加权轮叫” 调度算法根据真实服务器的不同处理能力来调度访问请求。这样可以保证处理能力强的服务器处理更多的访问流量。调度器可以自动问询真实服务器的负载情况, 并动态地调整其权值。

3）DH：目标地址散列调度（Destination Hash ）  
根据请求的目标 IP 地址，作为散列键 (HashKey) 从静态分配的散列表找出对应的服务器，若该服务器是可用的且未超载，将请求发送到该服务器，否则返回空。

4）  SH：源地址 hash（Source Hash）  
源地址散列”调度算法根据请求的源 IP 地址，作为散列键 (HashKey) 从静态分配的散列表找出对应的服务器，若该服务器是可用的且未超载，将请求发送到该服务器，否则返回空｡

常用的动态调度算法有下面这些

1）LC：最少链接（Least Connections）  
调度器通过” 最少连接” 调度算法动态地将网络请求调度到已建立的链接数最少的服务器上。如果集群系统的真实服务器具有相近的系统性能，采用” 最小连接” 调度算法可以较好地均衡负载。

2）WLC：加权最少连接 (默认采用的就是这种)（Weighted Least Connections）  
在集群系统中的服务器性能差异较大的情况下，调度器采用 “加权最少链接” 调度算法优化负载均衡性能，具有较高权值的服务器将承受较大比例的活动连接负载｡调度器可以自动问询真实服务器的负载情况, 并动态地调整其权值。

3）SED：最短延迟调度（Shortest Expected Delay ）  
在 WLC 基础上改进，Overhead = （ACTIVE+1）*256 / 加权，不再考虑非活动状态，把当前处于活动状态的数目 + 1 来实现，数目最小的，接受下次请求，+1 的目的是为了考虑加权的时候，非活动连接过多缺陷：当权限过大的时候，会倒置空闲服务器一直处于无连接状态。

4）NQ 永不排队 / 最少队列调度（Never Queue Scheduling NQ）  
无需队列。如果有台 realserver 的连接数＝0 就直接分配过去，不需要再进行 sed 运算，保证不会有一个主机很空闲。在 SED 基础上无论 + 几，第二次一定给下一个，保证不会有一个主机不会很空闲着，不考虑非活动连接，才用 NQ，SED 要考虑活动状态连接，对于 DNS 的 UDP 不需要考虑非活动连接，而 httpd 的处于保持状态的服务就需要考虑非活动连接给服务器的压力

**文章来自一点资讯运维团队**