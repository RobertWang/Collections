> 本文由 [简悦 SimpRead](http://ksria.com/simpread/) 转码， 原文地址 [mp.weixin.qq.com](https://mp.weixin.qq.com/s?__biz=MjM5NTY1MjY0MQ==&mid=2650852053&idx=4&sn=a9a758bfcd0c8010d60ec970c3231bb9&chksm=bd015f9b8a76d68ded7bad4231a2d2950ef2ec35b32dad58e2a2b782d9e5f1a9f2d17481116e&scene=21#wechat_redirect)

_________出处：捉虫大师（ID：gh_562cbc6dd343）_________  

_________如若转载请联系原公众号_________

### 背景

![](https://mmbiz.qpic.cn/sz_mmbiz_png/xacdaKuBM0QMLm5ob22BJeS4lMiask4LPxa0Z8G577Ll6JIru2ib51KDHTwOzRDKwMd2Q7aDzdxm7I44ZDpibEDOA/640?wx_fmt=png)

*   Consumer 和 Provider 的服务发现请求（注册、注销、订阅）都发给 Agent，由它全权代理
    
*   Registry 和 Agent 保持 Grpc 长链接，长链接的目的主要是 Provider 方有变更时，能及时推送给相应的 Consumer。为了保证数据的正确性，做了推拉结合的机制，Agent 会每隔一段时间去 Registry 拉取订阅的服务列表
    
*   Agent 和业务服务部署在同一台机器上，类似 Service Mesh 的思路，尽量减少对业务的入侵，这样就能快速的迭代了
    

这里的`Registry`就是今天的主角，熟悉 Dubbo 的朋友可以把它当做是一个 zookeeper，不熟悉的朋友可以就把它当做是一个 Web 应用，提供了注册、注销、订阅接口，虽然它是用 Go 写的，但本文和 Go 本身关系不大，也会用一些伪代码来示意，所以也可以放心大胆地看下去。

### 一定要做性能优化吗

*   减少资源消耗，降低成本
    
*   提高系统稳定性
    

回到这个注册中心，为什么要做性能优化呢？

Dubbo 应用启动时，会向注册中心发起注册，如果注册失败，则会阻塞应用的启动。

起初这个项目问题并不大，因为接入的应用并不多，而当我接手项目时，接入的应用越来越多。

话分两头，另一边集团也在逐渐使用容器替代虚拟机和物理机，在高峰期会用扩容的方式来抗住流量高峰，快速扩容就要求服务能在短时间内大量启动，无疑对注册中心是一个大的考验。

而导致这次优化的直接导火索是集团内的一次演练，他们发现一个配置中心的启动依赖，性能达不到标准而导致扩容失败，于是复盘下来，所有的启动依赖必须达到一定的性能要求，而这个标准被定为 1000qps。

于是就有了本文。

### 指标度量

如果不能度量，就没法优化。

### 瓶颈在哪里

性能优化的最关键之处在于找到瓶颈在哪，否则就是无头苍蝇，到处瞎碰。

注册接口到底干了什么呢？我这里画个简图

![](https://mmbiz.qpic.cn/sz_mmbiz_png/xacdaKuBM0QMLm5ob22BJeS4lMiask4LPCKwOmGYEhu3LGsib0EBLjX0NaO1OatNsoSj5UvUFDPNwsGMFOdstGiaQ/640?wx_fmt=png)

*   整个流程加锁，防止并发操作
    
*   Create App 和 Create Cluster 是创建应用和集群，只会在应用第一次创建，如果创建过就直接跳过
    
*   Insert Endpoint 是插入注册数据，即 ip 和 port
    
*   系统的底层存储是基于 MySQL，Lock 和 UnLock 也是基于 MySQL 实现的悲观锁
    

从这个流程图就能看出来，瓶颈大概率在锁上，这是个悲观锁，而且粒度是 App，把整个流程锁住，同一时刻相同应用的请只允许一个通过，可想而知性能有多差。

至于 MySQL 如何实现一个悲观锁，我相信你会的，所以我就不展开。

为了证明猜想，我用了一个非常笨但很有效的方法，在每一个关键节点执行之后，记录下耗时，最后打印到日志里，这样就能一眼看出到底哪里慢，果然最慢的就是加锁。

### 锁优化

在优化锁之前，我们先搞清楚为什么要加锁，在我反复测试，读代码，看文档之后，发现事情其实很简单，这个锁是为了防止 App、Cluster、Endpoint 重复写入。

为什么防止重复写入要这么折腾呢？一个数据库的唯一索引不就搞定了？这无法考证，但现状就是这样，如何破解呢？

*   首先是看这些表能否加唯一索引，有则尽量加上
    
*   其次数据库悲观锁能否换成 Redis 的乐观锁？
    

这个其实是可以的，原因在于客户端具有重试机制，如果并发冲突了，则发起重试，我们堵这个概率很小。

上面两条优化下来只解决了部分问题，还有的表实在无法添加唯一索引，比如这里 App、Cluster 由于一些特殊原因无法添加唯一索引，他们发生冲突的概率很高，同一个集群发布时，很可能是 100 台机器同时拉起，只有一台成功，剩余 99 台在创建 App 或者 Cluster 时被锁挡住了，发起重试，重试又可能冲突，大家都陷入了无限重试，最终超时，我们的服务也可能被重试流量打垮。

这该怎么办？这时我想起了刚学 Java 时练习写单例模式中，有个叫「双重校验锁」的东西，我们看代码

再结合我们的场景，App 和 Cluster 只在创建时需要保证唯一性，后续都是先查询，如果存在就不需要再执行插入，我们写出伪代码

```
app = DB.get("app_name")
if app == null {
    redis.lock()
    app = DB.get("app_name")
    if app == null {
        app = DB.instert("app_name")
    }
    redis.unlock()
}


```

是不是和双重校验锁一模一样？为什么这样会性能更高呢？因为 App 和 Cluster 的特性是只在第一次时插入，真正需要锁住的概率很小，就拿扩容的场景来说，必然不会走到锁的逻辑，只有应用初次创建时才会真正被 Lock。

### 读走缓存

于是将信息基本不变的对象加上了缓存，再测试，发现 qps 从 430 提升到了 440，提升不是很多，但苍蝇再小，好歹是块肉。

### CPU 优化

上一轮的优化效果不理想，但在压测时注意到了一个问题，我发现 Registry 的 CPU 降低的很厉害，感觉瓶颈从锁转移到了 CPU。说到 CPU，这好办啊，上火焰图，Go 自带的 pprof 就能干。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/xacdaKuBM0QMLm5ob22BJeS4lMiask4LPaicVxV8fkz9o9Pv6Eoib8bhf5XVDDtAGOB4X3J2vVgJiaFdnMLMd8fEbA/640?wx_fmt=jpeg)

可以清楚地看到是 ParseUrl 占用了太多的 CPU，这里简单科普下，Dubbo 传参很多是靠 URL 传参的，注册中心拿到 Dubbo 的 URL，需要去解析其中的参数，比如 ip、port 等信息就存在于 URL 之中。

一开始拿到这个 CPU profile 的结果是有点难受的，因为 ParseUrl 是封装的标准包里的 URL 解析方法，想要写一个比它还高效的，基本可以劝退。

但还是顺腾摸瓜，看看哪里调用了这个方法。不看不知道，一看吓一跳，原来一个请求里的 URL，会执行过程中多次解析 URL，为啥代码会这么写？可能是其中逻辑太复杂，一层一层的嵌套，但各个方法之间的传参又不统一，所以带来了这么糟糕的写法，

这种情况怎么办呢？

*   重构，把 URL 的解析统一放在一个地方，后续传参就传解析后的结果，不需要重复解析
    
*   对 URL 解析的方法，以每次请求的会话为粒度加一层缓存，保证只解析一次
    

我选择了第二种方式，因为这样对代码的改动小，毕竟我刚接手这么庞大、混乱的代码，最好能不动就不动，能少动就少动。

而且这种方式我很熟悉，在 Dubbo 的源码中就有这样的处理，Dubbo 在反序列化时，如果是重复的对象，则直接走缓存而不是再去构造一遍，代码位于`org.apache.dubbo.common.utils.PojoUtils#generalize`

截取一点感受下

```
private static Object generalize(Object pojo, Map<Object, Object> history) {
    ...
    Object o = history.get(pojo);
    if (o != null) {
        return o;
    }
    history.put(pojo, pojo);
    ...
}


```

根据这个思路，把 ParseUrl 改成带 cache 的模式

```
func parseUrl(url, cache) {
    if cache.get(url) != null {
        return cache.get(url)
    }
    u = parseUrl0(url)
    cache.put(url, u)
    return u
}


```

因为是会话级别的缓存，所以每个会话会 new 一个 cache，这样能保证一个会话中对相同的 url 只解析一次。

可以看下这次优化的成果，qps 直接到 1100，达到目标~

![](https://mmbiz.qpic.cn/sz_mmbiz_png/xacdaKuBM0QMLm5ob22BJeS4lMiask4LPdbfXYwkiaZdfW9lBJjQV6Ra1e6FLNp7ibwglJe7Gpziakv8H0LXv9O3Fg/640?wx_fmt=png)

### 最后说两句

可能有人看完就要喷了，这哪是性能优化？这分明是填坑！对，你说的没错，只不过这坑是别人挖的。

本文就以一种最小的代价来搞定对祖传代码的性能优化，当然并不是鼓励大家都去取巧，这项目我也正在重构，只是每个阶段都有不同的解法，比如老板要求你 2 周内接手一个新项目，并完成性能优化上线，重构是不可能的。

希望通过本文你能学到一些性能优化的基本知识，从为什么要做的拷问出发，建立度量体系，找出瓶颈，一步一步进行优化，根据数据反馈及时调整优化方向。

**<END>**