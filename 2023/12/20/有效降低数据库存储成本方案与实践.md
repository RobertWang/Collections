> 本文由 [简悦 SimpRead](http://ksria.com/simpread/) 转码， 原文地址 [mp.weixin.qq.com](https://mp.weixin.qq.com/s/ymb_kXvCFeYCqffa-lZeyw)

导读
--

在互联网行业降本增效的大背景下，如何治理成本投入重灾区——数据库（Mysql）成为了开发人员眼中的头等大事，本文介绍了降低数据库成本的方法与思路，并且介绍了在实践过程中需要着重关注的风险点与抵御风险的措施。
















================================================================================================================================

  

  

**01** 

**背景**

  

  

在今年的敏捷团队建设中，我通过 Suite 执行器实现了一键自动化单元测试。Juint 除了 Suite 执行器还有哪些执行器呢？由此我的 Runner 探索之旅开始了！

核心挑战有以下几个方面：

**数据安全问题：**无论是删数据，做压缩，冷热分离，对于已经占据 100T 磁盘空间的存储系统都是困难的操作，一个不小心，数据丢失了，或者无法正常获取数据了，这些问题对部门、对公司都会造成巨大损失。

  

  

**03** 

 

**体系化方法**
=========

 

  

  

理解，首先 MCube 会依据模板缓存状态判断是否需要网络获取最新模板，当获取到模板后进行模板加载，加载阶段会将产物转换为视图树的结构，转换完成后将通过表达式引擎解析表达式并取得正确的值，通过事件解析引擎解析用户自定义事件并完成事件的绑定，完成解析赋值以及事件绑定后进行视图的渲染，最终将目标页面展示到屏幕。

**九宫格**
-------

按逻辑梳理的办法，方案可针对**字段、表和库 3 个维度**，结合**删、减、缩 3 种策略**进行梳理，如删除表、清理部分表数据、压缩部分表的存储空间等。结合系统的实际情况，按照表格进行梳理，就能得到适合目标系统的成本降低方案了。

作者通过表格，结合账单系统实际情况，梳理出的执行的方案，**1、大表压缩，2、大 JSON 字段序列化，3、删除无效数据，4、无效表删除，5、无效索引删除，6、冷热分离**。

这么多的方案，总不能囫囵吞枣的瞎干吧，优先干哪个呢？它们的收益又是怎么样的呢？

  

  

**04** 

  **收益测算**  

  

  

理解，首先 MCube 会依据模板缓存状态判断是否需要网络获取最新模板，当获取到模板后进行模板加载，加载阶段会将产物转换为视图树的结构，转换完成后将通过表达式引擎解析表达式并取得正确的值，通过事件解析引擎解析用户自定义事件并完成事件的绑定，完成解析赋值以及事件绑定后进行视图的渲染，最终将目

在实际的方案阶段，都需要对方案产生的收益进行度量，再按照**投产比，决定方案执行的优先级**。

**测算方法**
--------

无论何种方案，测算起来无外乎**抽样、估算减少量、计算占比**几个过程。

举个例子：

以大 JSON 字段序列化为例，某个字段存储的是大 json 串，占用的字符比较多，因此对该字段做压缩，能够有效的降低磁盘占用空间。这个方案如何测算呢？思路是这样的，首先计算出目标大 json 字段占一条数据字符长度的比例，然后根据压缩比，得出压缩后该字段减少的字符数占比，之后抽样此表的 data 文件占的磁盘空间（如 3g），得出单表通过压缩后下降的磁盘空间（如 1.2g），最终再乘以该表的数量（如 20480），就能估算出最终减少的磁盘空间。最终计算公式：[压缩后减少的字符数 / 总字符数]* 单表空间 * 表数量 =[大 json 字符数 *（1 - 压缩比）/ 总字符数]* 单表空间 * 表数量 = 12t   磁盘减少占比：12t/95.9t=12%

如何得到字段的字符数？

可运用 **select LENGTH** 语法得出。具体计算可参照下表：

![](https://mmbiz.qpic.cn/mmbiz_png/RQv8vncPm1VsOehyUIl9PSiade79YO83iaarI7tWOw3fSRyZnQzPjyAntj0fXaqHdXiaalQXXZluxMn5DxjVxOhuA/640?wx_fmt=png&from=appmsg)

最终账单系统各方案的测算结果，大表压缩 32%，大 JSON 字段序列化 12%，删除无效数据 10%，无效表删除与无效索引删除都在 1% 左右。通过测算情况，我们就可以建立方案执行的优先级了，step1 大表压缩，step2 大 JSON 字段序列化，step3 删除无效数据等。冷热分离有收益，但是成本太高，可在日后架构升级中，再去考虑。

  

  

**05** 

  **数据安全与系统稳定性**  

  

  

理解，首先 MCube 会依据模板缓存状态判断是否需要网络获取最新模板，当获取到模板后进行模板加载，加载阶段会将产物转换为视图树的结构，转换完成后将通过表达式引擎解析表达式并取得正确的值，通过事件解析引擎解析用户自定义事件并完成事件的绑定，完成解析赋值以及事件绑定后进行视图的渲染，最终将目

前文提到过，无论采用何种方案，**数据安全与系统稳定性都需要验证的，数据丢失、或系统不可用、或降低用户体验下降过多都是不可接受的**。因此需要**保障这些情况尽量不要发生，或即使发生了，问题也在可控、可接受范围内**。

**方法**
------

### **黄金指标**

任何稳定性或安全性问题，都可通过 google SRE 的 4 个**黄金指标**去归纳，即**异常（exception）、耗时（tp99 等）、流量（tps）、饱和度（cpu、内存、磁盘、网络等）**。

可以结合目标系统的关键时段来看这 4 个黄金指标，例如大表压缩方案，那就可以关注压缩时的异常、耗时等，压缩后的异常耗时等等。

结合实际验证项

**压缩时：**1、读写耗时是否增加？2、吞吐量是否受到影响？3、压缩是否会产生异常？4、异常后压缩过程能否正常回滚？5、压缩是否会导致数据丢失？

**压缩后 & 大促高峰期：**1、读写耗时是否增加？2、吞吐量是否受到影响？3、压缩后大促流量是否能够应对？

这些问题如果有一项未验证或验证未通过，都不能执行压缩方案，因为方案执行后可能会对数据安全与系统稳定造成影响。

如何验证呢？

最严重的问题压缩是否会导致数据丢失，想通过一些方法验证这个问题非常困难的，只能通过 mysql 的压缩过程原理去分析。

![](https://mmbiz.qpic.cn/mmbiz_png/RQv8vncPm1VsOehyUIl9PSiade79YO83iaoWibKD1yqg37phHzibjvEuZUK6Af0qNGyZjFia17aBPJwq9tuvYT4J63A/640?wx_fmt=png&from=appmsg)

﻿﻿从官方文档中提炼出了 Online DDL 的 4 个步骤，从图中可看出，在任何阶段原表数据都不会丢失，直到完成切换后，原表才会被定期清理，因此压缩过程中数据是安全的。

第二个需要验证的是压缩时、压缩后与大促高峰期整个系统的读写耗时与吞吐量。

**第一步：搭建等比验证环境**

以文中账单系统实践为例，将生产的一个分库完全复制到一个新的物理机上，这样就以 20:1 的比例搭建了验证库。

![](https://mmbiz.qpic.cn/mmbiz_png/RQv8vncPm1VsOehyUIl9PSiade79YO83iaKFSZibUrHSeMVcIibxMoWicjiaHAujPRDaoBj4VgY3CKz4LkkblJk6ndRw/640?wx_fmt=png&from=appmsg)

**第二步：模拟流量**

这一步，需要结合目标系统的实际情况，完全模拟系统高峰期的流量，文中的账单系统是通过改造代码来达到流量预期的，如果所在部门原本就具备压测条件，可直接调整压测 robot 的流量开启压测程序来达到流量预期。

![](https://mmbiz.qpic.cn/mmbiz_png/RQv8vncPm1VsOehyUIl9PSiade79YO83iandlSUoEEyOpdaFmtroKUP9TYb7IvQsBO6paicgkOicR0EMiaBjZ6mDefg/640?wx_fmt=png&from=appmsg)

﻿﻿流量达标后，通过观察**压缩时或压缩后系统的吞吐量、写入的耗时以及慢 sql** 等情况，来判断压缩对系统及数据库的影响。如果此步发现了明显的慢 sql 或吞吐量异常，就需要**考量这些情况是否会影响系统的 SLA 指标，同时还要考量系统及业务能否容忍压缩所带来的负面影响**。

**压缩回滚问题**
----------

账单系统在做模拟流量压测时，意外的发生了异常，导致了压缩过程回滚。这也变相验证了，压缩过程是可回滚的。异常比较常见，duplicate key，这个异常是唯一索引重复导致。这个问题需要重视，因为账单系统会接收各种业务方的 mq 消息，难免会有这种重复下发过来的 mq，如果经常出现这种异常，最坏的情况是某些相关表永远无法压缩成功。如下图

![](https://mmbiz.qpic.cn/mmbiz_jpg/RQv8vncPm1VsOehyUIl9PSiade79YO83ia6icuXmb78SkET98xXd7xmK6rl6TvA14UjH5MBP5jzHGaLRicPC9wDMHA/640?wx_fmt=jpeg)

解决这个问题的方法很多，这里不赘述，但异常情况是做压缩过程中必须避免的。  

  

  

**06** 

  **方案落地**  

  

  

理解，首先 MCube 会依据模板缓存状态判断是否需要网络获取最新模板，当获取到模板后进行模板加载，加载阶段会将产物转换为视图树的结构，转换完成后将通过表达式引擎解析表达式并取得正确的值，通过事件解析引擎解析用户自定义事件并完成事件的绑定，完成解析赋值以及事件绑定后进行视图的渲染，最终将目

**灰度**
------

在方案的落地过程中，需要有灰度过程，来观察方案在生产环境中的执行是否会产生意料之外的问题。灰度的方法应视具体情况而定，但任何的灰度方案都应该至少**考虑故障、业务与性能 3 个方面**。

**（故障）影响范围控制：**以小见大，第一阶段的灰度一定是**以最细颗粒度方案进行落地**的，以便观察系统是否稳定、业务是否正常，这样即使出现意料之外的问题，影响的用户也是非常少的，不至于引起舆情。以表压缩为例，刚开始只压缩一张表，观察情况，随时准备回滚。

**（业务）全场景安全：**遵循灰度周期递减的方式，**第一阶段灰度开始时，经历的时间要足够长，确保新的内容已经经历过所有生产场景（all story）的考验**，这样能够保障新的内容在业务上是正确的，之后可以逐步的缩短验证周期，加快灰度进程。

**（性能）高流量验证：**高峰期考验，**每个灰度阶段都至少经历一个流量高峰期，来验证新内容的性能是否能够承受高峰流量**。为什么每个灰度阶段都要经历高峰期流量，第一阶段灰度的时候已经经历过一次高峰期流量验证了吗？这样做验证逻辑是有漏洞的，**系统作为一个整体，当其中大部分内容替换成新内容后，整个系统饱和度会随之产生变化**，如表压缩场景，是用时间换空间，因此可能影响系统的吞吐量，起初压缩一张表时，高峰期系统吞吐量可能并没有什么影响，之后压缩 100 张表后，高峰期系统开始有些流量积压，到最后 10000 张表压缩后，高峰期系统可能产生大量积压。像吞吐量这种宏观指标，在每个灰度阶段都必须关注。因此每个灰度阶段，都必须经历至少一个流量高峰期，才能证明系统的性能是没问题的。

**回滚**
------

在方案的灰度过程中，必须有相应的回滚手段，以便灰度产生问题后，能够及时的回滚止损。回滚方案中，需要注意的有两点，**1 是及时，2 是有效**，如压缩方案中的回滚方案是解压缩命令（通过 alter），及时提工单即可执行。

  

  

**07** 

  **总结**  

  

  

理解，首先 MCube 会依据模板缓存状态判断是否需要网络获取最新模板，当获取到模板后进行模板加载，加载阶段会将产物转换为视图树的结构，转换完成后将通过表达式引擎解析表达式并取得正确的值，通过事件解析引擎解析用户自定义事件并完成事件的绑定，完成解析赋值以及事件绑定后进行视图的渲染，最终将目

本文主要以介绍方法为主，落地过程可以归纳为方案 -> 收益测算 -> 数据安全验证 -> 系统稳定性验证 -> 灰度与回滚。文中的账单系统通过 step1 大表压缩 32%，step2 大 JSON 字段序列化 12%，step3 删除无效数据 10%，3 个方案的顺利落地，有效的减少了 50.7% 的磁盘空间，成本下降也非常显著。最后，希望此文能够给还在迷茫，不知从何处下手落地数据库存储成本降低的同学一些启发和灵感，以上。