> 本文由 [简悦 SimpRead](http://ksria.com/simpread/) 转码， 原文地址 [mp.weixin.qq.com](https://mp.weixin.qq.com/s/5QQ6VKiiQBRNyfRSS46k2A)

> 写在前面今天给大家带来一篇大模型外挂知识库优化技巧 - 如何更有效的利用召回的文档，来自战士金大佬（@知乎战士金

写在前面
----

今天给大家带来一篇大模型外挂知识库优化技巧 - 如何更有效的利用召回的文档，来自战士金大佬（@知乎战士金）。核心内容来自于论文《Lost in the Middle: How Language Models Use Long Contexts》。

```
Paper：https://arxiv.org/abs/2307.03172
知乎：https://zhuanlan.zhihu.com/p/651932402


```

在医学、法律、电商等垂类领域，大模型在训练时候可能没见过太多这些知识，模型就容易 “胡说八道”。虽然我们可以用特定领域再进行微调 / 二次预训练，仍然不能避免其 “胡说八道”，而且训练不好很可能 “灾难遗忘”，失去一些通用能力。

外挂数据库是解决模型 “胡说八道” 的有效手段。现在主流的外挂的数据库是向量数据库，因为实现起来比较简单，更复杂的也可以是图数据库、关系型数据库等。外挂数据库最简单的使用方式是，根据用户的问题，从数据库中召回若干条相关的文档片段，将文档片段和用户问题一块输入到大模型，让大模型根据文档片段回答用户的问题。**其实，大模型对输入中不同位置的文本信息利用能力是不同的，对召回的若干条文档片段进行合理的位置安排，能有效提高模型的回答效果。**

实验场景
----

（1）wiki 问答场景：大模型输入中包含一个问题和 k 个与问题相关的 wiki 文档片段，但是只有其中 1 个文档片段包含正确答案（数据集大部分都是 who/where 类型的，有精确答案，比较好评估）。做多次试验，每次分别将包含正确答案的文档片段放在不同的输入位置，并看模型模型回答问题的正确率。

（2）大模型输入为一个字典，包含若干对 key 和 value，key 和 value 都是无意义的 id 编号。问大模型某个 key，看其能否提取到对应的 value。和文档问答相比，该任务更简单的任务，也和实际使用场景偏离，本文不关心这部分数据的实验结果，感兴趣的可以看下原文，结论也差不多。下文的内容都是 wiki 问答场景的。

核心观点
----

大模型对上下文中中间部分的知识点提取较差。下图展示了，在大模型输入中放入 20 个文档片段，分别把包含正确答案的文档片段放到输入的不同位置上（1～20），chatgpt 能回答正确的概率。可以看到，如果包含正确答案的文本片段在中间位置，回答效果还不如不给他提供任何的文本片段（红色虚线，chatgpt 不借任何外部知识，在 wiki 问答场景下回答正确率也有 56.1%）。**也就是说，在模型知道一些对应知识的场景下，如果输入过长，并且正确答案在输入的中间部分，甚至会给模型效果带来负面影响。并不是说外挂了知识库一定能促进模型回答效果。**

![](https://mmbiz.qpic.cn/mmbiz_png/iceGibVicRfib5lOibibicvEqT17jWzQpaYRKNU3BWuf37XNic5th3ib6fle6GQiaEb9p68ibO29YcMI3nIaGczA0uiaHn4rvw/640?wx_fmt=png)

实验现象
----

上文提到，wiki 问答场景下，在输入里不给 chatgpt 提供任何额外知识，回答正确率都有 56.1%，相当于可接受的使用外挂知识库的准确率下限（如果低于这个值，那就还不如不外挂知识库了）。作者也尝试了输入里只放 1 个包含正确的答案的文档片段，回答正确率为 88%，相当于使用外挂知识库准确率的上限。

下图分别展示了不同模型在输入中分别放 10/20/30 个文档片段的实验结果（依然只有 1 个文档片段包含正确答案）。横坐标表示把包含正确答案的文档片段放到不同位置，纵坐标为准确率。从整体上来看，可以发现包含文档片段越多（上下文越长），模型性能越差。当文档片段数大于 20 时，如果把正确的文档片段放到中间位置，准确率还不如不加入任何文档片段（低于 56.1%）。普通 chatgpt 和声称支持更长上下文的 chatgpt-16k 效果差不多。

![](https://mmbiz.qpic.cn/mmbiz_png/iceGibVicRfib5lOibibicvEqT17jWzQpaYRKNUCMA7btveY2yHTDqFGT0icxqpCCL927Bc7mzdcEwMzo255xgD1W8JHlw/640?wx_fmt=png)

下边两张图展示了输入中包含 20 个文档片段的情况下，分别把 query 放到 context 尾部和 context 头部的实验效果。将 query 放到 context 头部效果更好。这非常符合直觉，实验的用的都是 decoder 架构的模型，只能看到上文的信息，带着问题去找答案更简单。

![](https://mmbiz.qpic.cn/mmbiz_png/iceGibVicRfib5lOibibicvEqT17jWzQpaYRKNU1kxiajye7cLBY1LhNibEzquZwAfCxWKIEtQvYvicWBSpxg0bpXCQwmjfg/640?wx_fmt=png)![](https://mmbiz.qpic.cn/mmbiz_png/iceGibVicRfib5lOibibicvEqT17jWzQpaYRKNUe61IIBbzRGjLoCUdwtUUib1XTiabAM1YhYLVPXaOWC9OW5pUM2ZHXecw/640?wx_fmt=png)

在实际应用场景下（该部分实验加入向量召回阶段，之前的实验没有召回阶段，都是把包含正确答案的文档片段直接塞到不同位置），向量召回可能是不准确的，召回的文档片段数量越多，漏掉正确答案的概率越小。但是如果召回的文档片段过多的话，导致输入到 LLM 的 context 过长，并不一定能有很好的效果。文中实验显示，随着召回的文档片段越来越多，召回率越高，召回阶段漏掉的正确文档越少（黄色曲线），但是模型回答的正确率并没有很大的提升，在召回 20 个文档片段的情况下基本就达到性能上线了。作者实验挑选的模型都是能支持比较长的文本的，大部分人使用的 chatglm 和 llama 估计能提取 10 个文档片段信息就不错了。。。当然，LLM 能提取多少个文档片段的内容也和每个文档片段的长度有关。文档片段长度最好别超过 100，不然会影响 embedding 模型向量化效果，进而使得召回精度降低。

![](https://mmbiz.qpic.cn/mmbiz_png/iceGibVicRfib5lOibibicvEqT17jWzQpaYRKNURrP9poLsVjZXGEsia76KurEo1nm8143ACsDmF1T300sX9lRwYEXtQ0A/640?wx_fmt=png)

总结
--

当我们召回若干个文档片段当作大模型的输入，应该怎么对这些文档片段进行排列，提高大模型回答效果呢？![](https://mmbiz.qpic.cn/mmbiz_png/iceGibVicRfib5lOibibicvEqT17jWzQpaYRKNUJ0o8ibFUPjyXsubG0hMjOGiaicPOyqdWmdKnicdGV5UXeZFyB6E1A1oAUQ/640?wx_fmt=png)如图所示，遵循两个原则：1. query 放到头部。2. 根据相似度（cos 相似度，点积等）召回的文档，相似度越大的文档放到 context 的两端。（图中 doc 的序号指按召回相似度从大到小排序后的序号）